{
  "hash": "faa3e1b29240374f439b4d0a4f9cc036",
  "result": {
    "markdown": "# Dirichlet Processes and Hidden Markov Model Transition Matrices\n\nHow do we construct transition matrices that prioritize re-entry into a constrained set of states? Especially if we don't have perfect knowledge of how many _true_ states there are?\n\nFrom [Matt Johnson's thesis](https://people.csail.mit.edu/mattjj/thesis/ch3.pdf), I learned exactly how.\n\nSome of us might be used to thinking about transition matrices that have strong diagonals.\nThat's all good for providing _stability_ in a sequence of transitions.\nBut if the goal is to provide a model\nwhere the constrained set of states is given priority over the other states,\nthen what we _really_ need is a transition matrix where the first K _columns_ of the transition matrix\nare given priority over the others.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n%load_ext watermark\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom jax import random, vmap, jit, grad, lax\nfrom jax.scipy import stats\nimport jax.numpy as np\nimport matplotlib.pyplot as plt\nfrom functools import partial\nimport seaborn as sns\n```\n:::\n\n\nTo generate a transition matrix with this desired property,\nwe can turn to the [GEM distribution][gem].\nThe GEM distribution is one way to generate a random vector\nfrom a Dirichlet distribution\n(which is the generalization of a Beta distribution).\n\nYou can think of it as stick-breaking, basically.\nWe take a stick of unit length 1,\nand break it in two according to a draw from a Beta distribution.\nWe record the length of the left part of the stick,\nand then break the right stick into two according to a draw from a Beta distribution.\nWe then record the new length of the left side and break the right one again and again,\n_ad infinitum_ or until we have reached a predefined (but finite) number of breaks.\nThe vector of recorded lengths becomes a \"weighting\" vector.\nOne thing to keep in mind: this weighting vector doesn't necessarily sum to 1,\nso in order to use the weighting vector in a transition matrix,\nwe do have to normalize it to sum to 1,\nor we append the remainder of the stick to the end to get it to sum to 1.\n\nEnough said, let's dig in and try simulating this process.\n\nFirstly, we generate a vector of i.i.d. draws from a Beta distribution with parameters $\\alpha = 1$ and $\\beta = 1$.\n\n[gem]: https://towardsdatascience.com/behind-the-models-beta-dirichlet-and-gem-distributions-526b11a24359\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nkey = random.PRNGKey(45)  # for reproducibility\nbeta_draws = random.beta(key, a=1, b=1, shape=(10,))\nplt.plot(beta_draws, marker=\"o\")\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-4-output-1.png){width=571 height=411}\n:::\n:::\n\n\nNow, we take this and begin our stick-breaking process. Because it is effectively a for-loop in which each loop iteration uses carryover from the previous loop iteration, I have written it taking advantage of JAX's `lax.scan` function.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef stick_breaking_weights(beta_draws):\n    \"\"\"Return weights from a stick breaking process.\n\n    :param beta_draws: i.i.d draws from a Beta distribution.\n        This should be a row vector.\n    \"\"\"\n    def weighting(occupied_probability, beta_i):\n        \"\"\"\n        :param occupied_probability: The cumulative occupied probability taken up.\n        :param beta_i: Current value of beta to consider.\n        \"\"\"\n        weight = (1 - occupied_probability) * beta_i\n        return occupied_probability + weight, weight\n\n    occupied_probability, weights = lax.scan(weighting, np.array(0.), beta_draws)\n\n    weights = weights / np.sum(weights)\n    return occupied_probability, weights\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\noccupied_prob, weights = stick_breaking_weights(beta_draws)\nplt.plot(weights, marker=\"o\")\nplt.ylim(-0.1, 1.1)\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-6-output-1.png){width=571 height=411}\n:::\n:::\n\n\nReally cool! We now have a vector of weights, normalized to a probability distribution.\n\nIt's worth at this point exploring the effect of varying the $b$ parameter in the Beta distribution:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 4), sharey=True)\n\nbvals = np.array([1, 3, 5, 10, 20])\nbeta_draws = vmap(partial(random.beta, key, 1, shape=(10,)))(bvals)\noccupied_probs, weights = vmap(stick_breaking_weights)(beta_draws)\n\nfor ax, weight, bval in zip(axes, weights, bvals):\n    ax.plot(weight, marker=\"o\")\n    ax.set_title(f\"b = {bval}\")\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-7-output-1.png){width=1538 height=357}\n:::\n:::\n\n\nAs should be visible, when we increase the `b` value, we get a less concentrated and flatter distribution compared to when we use a smaller `b` value. Thus, `b` acts as a \"concentration\" parameter. Smaller values means probability mass is concentrated on a smaller number of slots, while larger values means probability mass is diffused across a larger number of slots.\n\nHow does this relate to transition matrices in hidden Markov models? Well, a potentially desirable property is that we wish to express is that most of the states tend to move into a certain smaller number of states, thereby _concentrating_ the number of occupied states into a smaller set. This is equivalent to concentrating the transition matrix to a subset of _columns_. Let's see how we can generate this kind of transition matrix.\n\nFirstly, since transition matrices are square, let's start with a 15x15 transition matrix, i.e. one with 15 states.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nN_STATES = 15\nCONCENTRATION = 2\n\nbeta_draws = random.beta(key, a=1, b=CONCENTRATION, shape=(N_STATES, N_STATES))\n```\n:::\n\n\nTo visualize these i.i.d. Beta-distributed draws, let's use a heatmap.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nsns.heatmap(beta_draws);\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-9-output-1.png){width=533 height=411}\n:::\n:::\n\n\nKeep in mind, this is not the transition matrix just yet. It is the precursor to one!\n\nNext up, on a row-wise basis, we convert each row to a weighting vector, thereby getting back a transition matrix:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef compute_transition_matrix(beta_draws):\n    _, transition_matrix = vmap(stick_breaking_weights)(beta_draws)\n    return _, transition_matrix\n\n_, transition_matrix = compute_transition_matrix(beta_draws)\n```\n:::\n\n\nAnd visualizing the transition_matrix...\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nsns.heatmap(transition_matrix);\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-11-output-1.png){width=533 height=411}\n:::\n:::\n\n\nVoil√†! We have a transition matrix that has most of the probability mass concentrated in just a few states. Let's calculate the equilibrium distribution:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndef equilibrium_distribution(p_transition):\n    n_states = p_transition.shape[0]\n    A = np.append(\n        arr=p_transition.T - np.eye(n_states),\n        values=np.ones(n_states).reshape(1, -1),\n        axis=0\n    )\n    # Moore-Penrose pseudoinverse = (A^TA)^{-1}A^T\n    pinv = np.linalg.pinv(A)\n    # Return last row\n    return pinv.T[-1]\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\neq_distribution = equilibrium_distribution(transition_matrix)\nplt.plot(eq_distribution, marker=\"o\")\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-13-output-1.png){width=579 height=411}\n:::\n:::\n\n\nAs should be visible, we spend the majority of time in just a few states, and not too many more.\n\nAt this point, it's worth exploring how the \"concentration\" parameter affects the transition matrix, and hence the equilibrium distribution.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nCONCENTRATIONS = np.array([1, 3, 5, 10, 20])\nN_DIMS = 30\nbeta_draws = vmap(partial(random.beta, key, 1, shape=(N_DIMS, N_DIMS)))(CONCENTRATIONS)\nbeta_draws.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n(5, 30, 30)\n```\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n_, transition_matrices = vmap(compute_transition_matrix)(beta_draws)\neq_distributions = vmap(equilibrium_distribution)(transition_matrices)\n\nfig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 8))\n\nfor ax, conc, tmat in zip(axes[0, :], CONCENTRATIONS, transition_matrices):\n    sns.heatmap(tmat, ax=ax)\n    ax.set_title(f\"concentration = {conc}\")\n\nfor ax, conc, eq_dist in zip(axes[1, :], CONCENTRATIONS, eq_distributions):\n    ax.plot(eq_dist, marker=\"o\")\n    ax.set_title(f\"concentration = {conc}\")\n    ax.set_ylim(-0.1, 1.1)\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-15-output-1.png){width=1552 height=653}\n:::\n:::\n\n\nAs you can see, when the value of `b` goes up, the more diffuse the transition matrix, and the more evenly spread-out the equilibrium states will be.\n\n## Let's generate Markov sequences now\n\nNow that we know how to generate transition matrices, let's step back and try to see whether the generated Markovian sequences from these transition matrices make sense, i.e. whether they display the desired properties that we seek or not.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfrom jax import random\nfrom jax.scipy.special import logit\n```\n:::\n\n\nFirstly, let's try writing the function that generates a Markov sequence given a transition matrix.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfrom typing import List\nfrom jax import jit\n\ndef markov_sequence(key, p_transition: np.array, sequence_length: int) -> List[int]:\n    \"\"\"\n    Generate a Markov sequence based on p_init and p_transition.\n\n    Strategy: leverage categorical distribution.\n    We need to vmap over split PRNGKeys, which will give us the desired number of draws.\n    \"\"\"\n    p_eq = equilibrium_distribution(p_transition)\n    logit_p_eq = logit(p_eq)\n    initial_state = random.categorical(key, logits=logit_p_eq, shape=(1,))\n\n    def draw_state(prev_state, key):\n        logits = logit(p_transition[prev_state])\n        state = random.categorical(key, logits=logits, shape=(1,))\n        return state, state\n\n    keys = random.split(key, sequence_length)\n    final_state, states = lax.scan(draw_state, initial_state, keys)\n    return final_state, np.squeeze(states)\n\nmarkov_sequence = jit(markov_sequence, static_argnums=(2,))\n\nfinal, sequence = markov_sequence(key, transition_matrices[0], 100)\nfinal, sequence\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n(Array([0], dtype=int32),\n Array([0, 1, 2, 1, 0, 0, 3, 0, 1, 0, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 0,\n        0, 1, 0, 4, 1, 0, 7, 0, 1, 0, 1, 2, 0, 2, 4, 0, 0, 1, 2, 1, 2, 1,\n        0, 1, 4, 5, 0, 1, 0, 5, 0, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 2, 0, 3,\n        0, 1, 1, 1, 4, 1, 4, 1, 2, 1, 0, 1, 2, 1, 0, 3, 0, 1, 5, 0, 1, 2,\n        1, 0, 1, 0, 1, 0, 3, 0, 1, 0, 1, 0], dtype=int32))\n```\n:::\n:::\n\n\nNow, I think we can generate a bunch of Markov chain sequences using `vmap`.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ndef markov_seq_vmappable(key, transition_matrix):\n    sequence_length = 500\n    return markov_sequence(key, transition_matrix, sequence_length)\n\n_, sequences = vmap(markov_seq_vmappable)(random.split(key, 5), transition_matrices)\n```\n:::\n\n\nLet's plot them out!\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nimport seaborn as sns\n\nfig, axes = plt.subplots(figsize=(16, 20), nrows=5, ncols=1)\n\nfor ax, seq in zip(axes, sequences):\n    ax.plot(range(len(seq)), seq, marker=\"o\")\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-19-output-1.png){width=1236 height=1520}\n:::\n:::\n\n\nAs should be visible, as we increase the concentration parameter (really, I think this should be renamed as a \"diffusion\" parameter),\nthe number of states that we would typically¬†occupy increases. At smaller values of the concentration parameter, the number of states we would typically occupy decreases.\n\n## Generating Markov sequences concentrated on a few stable states\n\nWe've thus far generated transition matrices that are biased towards a few states, but they do tend to be jumpy, as the above scatterplots show. In other words, we have not yet generated matrices that allow for _stability inside a state_. Stability inside a state is generated from strong diagonals. We can engineer this in the generation of the matrix by leveraging (once again) the Beta distribution. Specifically, the generative story here is that each row of the transition matrix is generated by stick-breaking, but the diagonals are replaced by a Beta draw that is biased towards high probabilities. Let's see this in action for one transition matrix.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ndef diagonal_draws(key, bias_factor, shape):\n    return random.beta(key, a=bias_factor, b=1, shape=shape)\n```\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\ndd = diagonal_draws(key, bias_factor=50, shape=(N_DIMS,))\ndom_diag_transition_matrix = transition_matrices[0] + np.diagflat(dd)\n\ndef normalize_prob_vect(v):\n    return v / np.sum(v)\n\ndef normalize_transition_matrix(transition_matrix):\n    return vmap(normalize_prob_vect)(transition_matrix)\n\ndom_diag_transition_matrix = normalize_transition_matrix(dom_diag_transition_matrix)\nsns.heatmap(dom_diag_transition_matrix);\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-21-output-1.png){width=533 height=415}\n:::\n:::\n\n\nNow given _this_ transition matrix, let's generate new sequences:\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n_, seq = markov_sequence(key, dom_diag_transition_matrix, 500)\nplt.plot(seq, marker=\"o\")\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-22-output-1.png){width=558 height=411}\n:::\n:::\n\n\nAs is visible from the plot above, we get sequences that tend to stay inside a state, and when they do venture out to unfavoured states (e.g. state 5), they quickly return back to a favoured state.\n\nNow, let's see what kind of sequences we get when we use the same dominant diagonal with different concentration parameters.\n\nFirstly, we generate a bunch of dominant diagonal matrices:\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nkeys = random.split(key, 5)\ndiagonals = vmap(partial(diagonal_draws, bias_factor=50, shape=(N_DIMS,)))(keys)\n\ndef create_dominant_diagonal(p_transition, diagonal):\n    p_transition = p_transition + np.diagflat(diagonal)\n    return normalize_transition_matrix(p_transition)\n\ndom_diag_transition_matrices = vmap(create_dominant_diagonal)(transition_matrices, diagonals)\n\nfig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 3))\n\nfor ax, mat in zip(axes, dom_diag_transition_matrices):\n    sns.heatmap(mat, ax=ax)\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-23-output-1.png){width=1537 height=268}\n:::\n:::\n\n\nNow, we generate a bunch of sequences.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n_, sequences = vmap(markov_seq_vmappable)(random.split(key, 5), dom_diag_transition_matrices)\n\nfig, axes = plt.subplots(figsize=(16, 20), nrows=5, ncols=1)\n\nfor ax, seq, conc in zip(axes, sequences, CONCENTRATIONS):\n    ax.plot(range(len(seq)), seq, marker=\"o\")\n    ax.set_title(f\"concentration = {conc}\")\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-24-output-1.png){width=1236 height=1540}\n:::\n:::\n\n\nAs should be visible from here, we now generate sequences that have a much higher propensity to stay within their own state, rather than jump around. Additionally, when there are more states \"available\" (i.e. concentration runs higher), we also see them stay within their own state rather than jump back down to the favoured states.\n\n## Inference of the right \"concentration\" of states\n\nGiven the transition matrix, can we infer the concentration parameter that best describes it? This is what we're going to try out here.\n\nWe start with a vanilla transition matrix generated from a `concentration = 1` setting, with no dominant diagonals. This is the easier setting to begin with:\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nsns.heatmap(transition_matrices[0]);\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-25-output-1.png){width=533 height=415}\n:::\n:::\n\n\nEach row of the transition matrix is generated by running a stick breaking process forward from Beta distributed draws. We can run the process backwards to get back our Beta-distributed matrix. Because there's division involved, I have opted to operate in logarithmic space instead, to avoid over/under-flow issues.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nfrom jax import lax\ndef beta_draw_from_weights(weights):\n    def beta_from_w(accounted_probability, weights_i):\n        \"\"\"\n        :param accounted_probability: The cumulative probability acounted for.\n        :param weights_i: Current value of weights to consider.\n        \"\"\"\n        denominator = 1 - accounted_probability\n        log_denominator = np.log(denominator)\n\n        log_beta_i = np.log(weights_i) - log_denominator\n\n        newly_accounted_probability = accounted_probability + weights_i\n\n        return newly_accounted_probability, np.exp(log_beta_i)\n    final, betas = lax.scan(beta_from_w, np.array(0.), weights)\n    return final, betas\n```\n:::\n\n\nAnd now, to sanity-check that it works:\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nbeta_draw = random.beta(key, a=1, b=3, shape=(15,))\n_, weights = stick_breaking_weights(beta_draw)\n_, beta_draw_hat = beta_draw_from_weights(weights)\nplt.plot(beta_draw, label=\"original\")\nplt.plot(beta_draw_hat, label=\"recovered\")\nplt.legend()\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-27-output-1.png){width=571 height=411}\n:::\n:::\n\n\nUp till the last few values, we are basically able to recover the beta distributed draw that generated the matrix. The fundamental problem we're facing here is that when we are faced with a probability vector, we're still missing the \"last stick\" which would give us an accurate estimate of the originals. As such, only the first few are really accurate, and the accuracy of beta draw recovery goes down as we go across the vector.\n\nLet's now apply the function to every row in the transition matrix.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\ndef recover_beta(transition_matrix):\n    return vmap(beta_draw_from_weights)(transition_matrix)\n```\n:::\n\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n_, recovered_betas = vmap(recover_beta)(transition_matrices)\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n\nidx = 4\nsns.heatmap(recovered_betas[idx], ax=axes[0])\nsns.heatmap(beta_draws[idx], ax=axes[1])\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n<AxesSubplot: >\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-29-output-2.png){width=789 height=342}\n:::\n:::\n\n\nMatches what we saw above - we're doing an almost-OK job here.\n\nNow, we can evaluate the logpdf of the matrix.\nBecause each entry in the recovered betas matrix is an i.i.d. draw from the Beta distribution,\nand because row-wise the first 3-5 elements are accurately estimatable backwards from the weights,\nwe will estimate the concentration parameter using only the first three columns of betas from the matrix.\n\nTest-driving the syntax below...\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nnp.sum(stats.beta.logpdf(recovered_betas[4, :, :3], a=1, b=9))\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\nArray(153.58696, dtype=float32)\n```\n:::\n:::\n\n\nLooks good! Let's now define a function for the logpdf.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\ndef transition_matrix_logpdf(transition_matrix, concentration, num_cols=2):\n    _, beta_recovered = recover_beta(transition_matrix)\n    logp = stats.beta.logpdf(beta_recovered[:, :num_cols], a=1, b=concentration)\n    return np.sum(logp)\n\ntransition_matrix_logpdf(transition_matrices[1], 5)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\nArray(20.504595, dtype=float32)\n```\n:::\n:::\n\n\nJust to see if this is a gradient optimizable problem, let's plot a range of concentration values, and see what happens.\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nlog_conc_range = np.linspace(-3, 3, 10000)\nconc_range = np.exp(log_conc_range)\n\ndef loglike_range(transition_matrix, log_conc_range):\n    conc_range = np.exp(log_conc_range)\n    ll = vmap(partial(transition_matrix_logpdf, transition_matrix))(conc_range)\n    return ll\n\nll = loglike_range(transition_matrices[0], log_conc_range)\n\nlls = vmap(partial(loglike_range, log_conc_range=log_conc_range))(transition_matrices)\n\nfig, axes = plt.subplots(nrows=1, ncols=len(CONCENTRATIONS), figsize=(20, 4))\n\nfor ll, conc, ax in zip(lls, CONCENTRATIONS, axes):\n    ax.plot(conc_range, ll)\n    ax.set_title(f\"concentration = {conc}\")\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-32-output-1.png){width=1562 height=357}\n:::\n:::\n\n\nNot bad! Visually, it appears that we do pretty good in recovering the maximum likelihood value for most of the entries, but for concentration = 20, it's more difficult to do so.\n\nLet's confirm by extracting the concentration at which we have maximum log-likelihood.\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nmaxes = vmap(np.argmax)(lls)\nmle_estimates = np.take(conc_range, maxes)\nmle_estimates\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\nArray([ 0.930245 ,  3.1544516,  5.2817965, 10.019469 , 16.261148 ],      dtype=float32)\n```\n:::\n:::\n\n\nGreat! Doing this brute-force is all nice and good, but one of the points of JAX is that we get to do gradient descent easily. So now, let's try to perform gradient-based optimization :).\n\nWe start by first defining a loss as a function of the log of the concentration. (We use the log so that when we do gradient optimization, we can be in an unbounded space.) We also define the gradient of the loss function.\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\ndef loglike_loss(log_concentration, transition_matrix):\n    concentration = np.exp(log_concentration)\n    ll = transition_matrix_logpdf(transition_matrix, concentration)\n    return -ll\n\nloglike_loss = jit(loglike_loss)\ndloglike_loss = grad(loglike_loss)\n```\n:::\n\n\nNext up, we do the loop. Instead of writing an explicit for-loop, we are going to some JAX trickery here:\n\n1. We write the loop taking advantage of `lax.scan`, which allows us to leverage the previous state to get back parameters to optimize.\n1. We also vmap our training loop over all 5 matrices, starting with the same log concentration starting point. This allows us to essentially train five models at one shot. (I could have `pmap`-ed it, but I really only have one CPU and one GPU on my computer.)\n1. Since the result is a vmapped, we have a collection of final states and historical states (which we can post-process post-hoc). Hence, we can vmap `get_params` over final states to get back the vector of final states (from a constant initial state).\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\nfrom jax.example_libraries.optimizers import adam\n\ninit, update, get_params = adam(0.05)\nlog_conc_start = random.normal(key)\n\ndef step(prev_state, i, data, dloss):\n    \"\"\"One step in the training loop.\"\"\"\n    params = get_params(prev_state)\n    g = dloss(params, data)\n    state = update(i, g, prev_state)\n    return state, state\n\ndef train(transition_matrix, dloss, params, n_steps=200):\n    \"\"\"The training loop for one transition matrix.\"\"\"\n    stepfunc = partial(step, data=transition_matrix, dloss=dloss)\n    stepfunc = jit(stepfunc)\n\n    state = init(params)\n    final_state, states = lax.scan(stepfunc, state, np.arange(n_steps))\n    return final_state, states\n\ntrainfunc = partial(train, params=log_conc_start, dloss=dloglike_loss)\ntrainfunc = jit(trainfunc)\n# Train across all transition matrices!\nfinal_states, states_history = vmap(trainfunc)(transition_matrices)\nnp.exp(vmap(get_params)(final_states))\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\nArray([ 0.9300743,  3.155341 ,  5.2777195, 10.022282 , 16.264479 ],      dtype=float32)\n```\n:::\n:::\n\n\nWe can also get the history by `vmap`-ing `get_params` over `all_states`.\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\nlog_concentration_history = vmap(get_params)(states_history)\n\nfor concentration, history in zip(CONCENTRATIONS, log_concentration_history):\n    plt.plot(np.exp(history), label=concentration)\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Concentration Value\")\nplt.legend()\nsns.despine()\n```\n\n::: {.cell-output .cell-output-display}\n![](generating-markov-chains-dirichlet_files/figure-html/cell-36-output-1.png){width=597 height=429}\n:::\n:::\n\n\nNow, if you're wondering how I knew 200 steps would be sufficient for convergence _a priori_, I didn't :). I had originally tried 1000 steps before staring at the concentration curves, at which point I then knew 200 was sufficient. So... no magic there.\n\n## Summary\n\nThis was a bit of a whirlwind tour of a notebook, in that there were many concepts and ideas tied together into one \"project\".\n\nWith respect to HMMs, it's super important to have a proper mental model of each of its components. In the case of _expressing_ the idea that we have a restricted number of states, we may _engineer_ this into the model by taking advantage of column-wise heaviness in a restricted subset of states. This is mathematically most naturally incorporated by composint together row-wise Dirichlet-distributed probability arrays. We can also mathematically _engineer_ consistency in states by taking advantage of high Beta-distributed values. Compose the two together, and we get a transition matrix that favours entry into a small number of states with stability in there.\n\nBeyond that lesson, we saw the power of composable programs using JAX. `vmap`, `jit`, `lax.scan`, and more from the JAX toolkit gives us the ability to write performant programs that sort of \"just make sense\", once you know what their idioms are. Specifically:\n\n- `vmap` is a vanilla for-loop, processing an elementary function over an axis of an array.\n- `lax.scan` is a carry-over for-loop, processing the result of a previous iteration, with accumulation of history as well.\n- `jit` gives you just-in-time compilation of a function.\n- `grad` gives you gradients of any arbitrary function written in a JAX-compatible, pure functional fashion.\n\nIn particular, getting used to the `lax.scan` idioms has been a literal door-opener. We can now write really performant loops that use results from previous iterations, such as a gradient descent training loop or an MCMC sampler. Using `lax.scan`, we wrote:\n\n- A Markov chain state generator\n- A generator of Dirichlet-distributed weights from i.i.d. Beta distribution draws\n- A reverse generator/estimator of Beta distribution draws from Dirichlet-distributed weights (with some inaccuracies of course, due to a lack of information).\n- A fully-compiled gradient descent training loop that ran extremely fast.\n\nAnd using `vmap`, we were able to do all sorts of vanilla loops, but the one I want to highlight is our ability to `vmap` the compiled training loop across multiple transition matrices. The fact that this _actually_ works never has left me in awe. Props to the JAX team here! Opens the door to `vmap`-ing training loops across random starting points (i.e. a split PRNGKey, much like what we did in the HMM state generator).\n\nThe trade-off is that we don't get nice progress bars, of course, which require that we break out of the compiled loop to show the current state. But the compilation speedups provided the opportunity to build our compiled tensor program end-to-end. We could verify first that things ran correctly on a moderately-sized number of iterations, before finally estimating how long we would need to go until convergence and letting the program run on its own. I'm sure this little change isn't too hard to adapt to, but will give you access to a whole new world of differential tensor programming that is just _cool_!\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\n%watermark\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLast updated: 2022-12-20T10:43:01.610330-05:00\n\nPython implementation: CPython\nPython version       : 3.10.8\nIPython version      : 8.7.0\n\nCompiler    : GCC 10.4.0\nOS          : Linux\nRelease     : 5.15.0-53-generic\nMachine     : x86_64\nProcessor   : x86_64\nCPU cores   : 8\nArchitecture: 64bit\n\n```\n:::\n:::\n\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n%watermark --iversions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmatplotlib: 3.6.2\njax       : 0.4.1\nseaborn   : 0.12.1\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "generating-markov-chains-dirichlet_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}
