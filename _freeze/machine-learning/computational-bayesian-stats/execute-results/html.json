{
  "hash": "9fb018f5399a2e1b7e17e578d12b91a1",
  "result": {
    "markdown": "# An Introduction to Probability and Computational Bayesian Statistics\n\nIn Bayesian statistics,\nwe often say that we are \"sampling\" from a posterior distribution\nto estimate what parameters could be,\ngiven a model structure and data.\nWhat exactly is happening here?\n\nExamples that I have seen on _how sampling happens_\ntends to focus on an overly-simple example\nof sampling from a single distribution with known parameters.\nI was wondering if I could challenge myself\nto come up with a _simplest complex example_\nthat would illuminate ideas that were obscure to me before.\nIn this essay, I would like to share that knowledge with you,\nand hopefully, build up your intuition behind\nwhat is happening in computational Bayesian inference.\n\n## Probability Distributions\n\nWe do need to have a working understanding\nof what a probability distribution is before we can go on.\nWithout going down deep technical and philosophical rabbit holes\n(I hear they are deep),\nI'll start by proposing\nthat \"a probability distribution is a Python object\nthat has a math function\nthat allocates credibility points onto the number line\".\n\nBecause we'll be using the normal distribution extensively in this essay,\nwe'll start by examining that definition\nin the context of the standard normal distribution.\n\n### Base Object Implementation\n\nSince the normal distribution is an object,\nI'm implying here that it can hold state.\nWhat might that state be?\nWell, we know from math that probability distributions have parameters,\nand that the normal distribution\nhas the \"mean\" and \"variance\" parameters defined.\nIn Python code, we might write it as:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nclass Normal:\n    def __init__(self, mu, sigma):\n        self.mu = mu\n        self.sigma = sigma\n```\n:::\n\n\n### Probability Density Function\n\nNow, I also stated that the normal distribution has a math function\nthat we can use to allocate credibility points to the number line.\nThis function also has a name,\ncalled a _probability density function_, or the _PDF_.\nUsing this, we may then extend this object\nwith a method called `.pdf(x)`,\nthat returns a number\ngiving the number of credibility points\nassigned to the value of `x` passed to it.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\n\nclass Normal:\n    def __init__(self, mu, sigma):\n        self.mu = mu\n        self.sigma = sigma\n\n    def pdf(self, x):\n        return (\n            1 / np.sqrt(2 * self.sigma ** 2 * np.pi)\n            * np.exp(\n                - (x - self.mu) ** 2\n                / 2 * self.sigma ** 2\n            ))\n```\n:::\n\n\nIf we pass in a number `x` from the number line,\nwe will get back another number that tells us\nthe number of credibility points given to that value `x`\nunder the state of the normal distribution instantiated.\nWe'll call this $P(x)$.\n\nTo simplify the implementation used here,\nwe are going to borrow some machinery already available to us\nin the Python scientific computing ecosystem,\nmainly from the SciPy stats module,\nwhich gives us reference implementations of probability distributions.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom scipy.stats import norm\n\nclass Normal:\n    def __init__(self, mu, sigma):\n        self.mu = mu\n        self.sigma = sigma\n\n        # We instantiate the distribution object here.\n        self.dist = norm(loc=mu, scale=sigma)\n\n    def pdf(self, x):\n        # Now, our PDF class method is simplified to be just a wrapper.\n        return self.dist.pdf(x)\n```\n:::\n\n\n### Log Probability\n\nA common task in Bayesian inference is computing the likelihood of data.\nLet's assume that the data ${X_1, X_2, ... X_i}$ generated\nare independent and identically distributed\n(the famous _i.i.d._ term comes from this).\nThis means, then, that the joint probability of the data that was generated\nis equivalent to the product of the individual probabilities of each datum:\n\n$$P(X_1, X_2, ... X_i) = P(X_1) P(X_2) ... P(X_i)$$\n\n(We have to know the rules of probability to see this result;\nit is a topic for a different essay.)\n\nIf you remember the notation above,\neach $P(X_i)$ is an evaluation of $X_i$\non the distribution's probability density function.\nIt being a probability value means it is bound between 0 and 1.\nHowever, multiplying many probabilities together\nusually will result in issues with underflow computationally,\nso in evaluating likelihoods,\nwe usually stick with log-likelihoods instead.\nBy the usual rules of math, then:\n\n$$\\log P(X_1, X_2, ..., X_i) = \\sum_{j=1}^{i}\\log P(X_i)$$\n\nTo our Normal distribution class,\nwe can now add another class method\nthat computes the sum of log-likelihoods\nevaluated at a bunch of i.i.d. data points.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom scipy.stats import norm\n\nclass Normal:\n    def __init__(self, mu, sigma):\n        self.mu = mu\n        self.sigma = sigma\n\n        # We instantiate the distribution object here.\n        self.dist = norm(loc=mu, scale=sigma)\n\n    def pdf(self, x):\n        # Now, our PDF class method is simplified to be just a wrapper.\n        return self.dist.pdf(x)\n\n    def logpdf(self, x):\n        return self.dist.logpdf(x)\n```\n:::\n\n\n## Random Variables\n\n### Definition\n\nInformally, a \"random variable\" is nothing more than\na variable whose quantity is non-deterministic (hence random)\nbut whose probability of taking on a certain value\ncan be described by a probability distribution.\n\nAccording to the Wikipedia definition of a [random variable][rv]:\n\n> A random variable has a probability distribution,\n> which specifies the probability of its values.\n\n[rv]: https://en.wikipedia.org/wiki/Random_variable\n\nAs such, it may be tempting to conceive of a random variable\nas an object that has a probability distribution attribute attached to it.\n\n### Realizations of a Random Variable\n\nOn the other hand, it can also be convenient to invert that relationship,\nand claim that a probability distribution\ncan generate realizations of a random variable.\nThe latter is exactly how SciPy distributions are implemented:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfrom scipy.stats import norm\n\n# Normal distribution can generate realizations of an RV\n# The following returns a NumPy array of 10 draws\n# from a standard normal distribution.\nnorm(loc=0, scale=1).rvs(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\narray([ 0.6932344 , -0.14991146,  0.57004881, -0.68375877,  1.74824313,\n       -0.94082983, -0.01542047, -1.75222145, -1.11863537,  1.37376201])\n```\n:::\n:::\n\n\n::: {.callout-note}\n## Realizations of a Random Variable\n\nA \"realization\" of a random variable is nothing more than\ngenerating a random number\nwhose probability of being generated\nis defined by the random variable's probability density function.\n:::\n\nBecause the generation of realizations of a random variable\nis equivalent to sampling from a probability distribution,\nwe can extend our probability distribution definition\nto include a `.sample(n)` method:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom scipy.stats import norm\n\nclass Normal:\n    def __init__(self, mu, sigma):\n        self.mu = mu\n        self.sigma = sigma\n\n        # We instantiate the distribution object here.\n        self.dist = norm(loc=mu, scale=sigma)\n\n    # ...\n\n    def sample(self, n):\n        return self.dist.rvs(n)\n```\n:::\n\n\nNow, if we draw ten realizations of a normally distributed random variable,\nand the drawing of each realization has no dependence on the previous draw,\nthen we can claim that each draw is **independent**\nand **identically distributed**.\nThis is where the fabled \"_iid_\" term in undergraduate statistics classes\ncomes from.\n\n## Data Generating Process\n\nNow that we have covered what probability distributions are,\nwe can now move on to other concepts\nthat are important in Bayesian statistical modeling.\n\nRealizations of a random variable,\nor draws from its probability distribution,\nare how a Bayesian assumes data are generated.\nDescribing how data are generated using probability distributions,\nor in other words, writing down the _data-generating process_,\nis a core activity in Bayesian statistical modeling.\n\nViewed this way, data values generated by a random process\ndepend on the underlying random variable's probability distribution.\nIn other words, the random variable realizations are known,\ngiven the probability distribution used to model it.\nKeep this idea in mind:\nIt is going to be important shortly.\n\n## Bayes' Rule\n\nNow that we've covered probability distributions,\nwe can move on to Bayes' rule.\nYou probably have seen the following equation:\n\n$$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$$\n\nBayes' rule states nothing more than the fact that\nthe conditional probability of B given A is equal to\nthe conditional probability of A given B\ntimes the probability of B\ndivided by the probability of A.\n\nWhen performing Bayesian statistical inference,\nwe commonly take a related but distinct interpretation:\n\n$$P(H|D) = \\frac{P(D|H)P(H)}{P(D)}$$\n\nIt may look weird,\nbut didn't we say before that data are realizations from a random variable?\nSo why are we now treating data as a random variable?\nHere, we are doing a not-so-intuitive but technically correct step\nof treating the data $D$ as part of this probabilistic model\n(hence it \"looks\" like a random variable),\nalongside our model parameters $H$.\nThere's a lot of measure theory that goes into this interpretation,\nwhich, at this point, I have not yet mastered,\nand so will wave my hands in great arcs\nand propose that this interpretation be accepted for now and move on.\n\n::: {.callout-note}\n## Data are random variables?\n\nNotes from a chat with Colin gave me a lot to chew on, as usual:\n\n> The answer is in how you define \"event\" as\n> \"an element of a sigma-algebra.\"\n> intuitively, an \"event\" is just an abstraction,\n> so one event might be \"the coin is heads,\"\n> or in another context, the event might be\n> \"the parameters are [0.2, 0.1, 0.2]\".\n> And so analogously, \"the data were configured as [0, 5, 2, 3]\".\n> Notice also that the events are different\n> if the data being ordered vs. unordered are different!\n\nThis was a logical leap that I had been asked about before,\nbut did not previously have the knowledge to respond.\nThanks to Colin, I now do.\n\n[colin]: https://colindcarroll.com/\n:::\n\nWith the data + hypothesis interpretation of Bayes' rule in hand,\nthe next question arises:\nWhat math happens when we calculate posterior densities?\n\n## Translating Bayes' Math to Python\n\n### Defining Posterior Log-Likelihood\n\nTo understand this, let's look at the simplest complex example\nthat I could think of:\nEstimating the $\\mu$ and $\\sigma$ parameters\nof a normal distribution\nconditioned on observing data points $y$.\n\nIf we assume a data generating process that looks like the following\n(with no probability distributions specified yet):\n\n\n```{mermaid}\ngraph TD;\n    μ((μ)) --> y(y);\n    σ((σ)) --> y(y);\n```\n\n\nWe can write out the following probabilistic model\n(now explicitly specifying probability distributions):\n\n$$\\mu \\sim Normal(0, 10)$$\n\n$$\\sigma \\sim Exponential(1)$$\n\n$$y \\sim Normal(\\mu, \\sigma)$$\n\nLet's now map the symbols onto Bayes' rule.\n\n- $H$ are the parameters, which are $\\mu$ and $\\sigma$ here.\n- $D$ is the data that I will observe\n- $P(H|D)$ is the posterior, which we would like to compute.\n- $P(D|H)$ is the likelihood,\nand is given by $y$'s probability distribution $Normal(\\mu, \\sigma)$,\nor in probability notation, $P(y|\\mu, \\sigma)$.\n- $P(H)$ is the the prior, and is given by $P(\\mu, \\sigma)$.\n- $P(D)$ is a hard quantity to calculate, so we sort of cheat and don't use it,\nand merely claim that the posterior is proportional to likelihood times prior.\n\nIf we look at the probability symbols again,\nwe should notice that $P(\\mu, \\sigma)$\nis the joint distribution between $\\mu$ and $\\sigma$.\nHowever, from observing the graphical diagram,\nwe'll notice that $\\mu$ and $\\sigma$ have no bearing on one another:\nwe do not need to know $\\mu$ to know the value of $\\sigma$,\nand vice versa.\nHence, they are independent of one another,\nand so by the rules of probability,\n\n$$P(\\mu, \\sigma) = P(\\mu | \\sigma)P(\\sigma) = P(\\mu)P(\\sigma) = P(H)$$\n\nNow, by simply moving symbols around:\n\n$$P(H|D) = P(D|H)P(H)$$\n\n$$ = P(y|\\mu,\\sigma)P(\\mu, \\sigma)$$\n\n$$ = P(y|\\mu, \\sigma)P(\\mu)P(\\sigma)$$\n\nThis translates directly into Python code!\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef model_prob(mu, sigma, y):\n    # Probability of mu under prior.\n    normal_prior = Normal(0, 10)\n    mu_prob = normal_prior.pdf(mu)\n\n    # Probability of sigma under prior.\n    sigma_prior = Exponential(1)\n    sigma_prob = sigma_prior.pdf(sigma)\n\n    # Likelihood of data given mu and sigma\n    likelihood = Normal(mu, sigma)\n    likelihood_prob = likelihood.pdf(y).prod()\n\n    # Joint likelihood\n    return mu_prob * sigma_prob * likelihood_prob\n```\n:::\n\n\nIf you remember, multiplying so many probability distributions together\ncan give us underflow issues when computing,\nso it is common to take the log of both sides.\n\n$$\\log(P(H|D)) = log(P(y|\\mu, \\sigma)) + log(P(\\mu)) + log(P(\\sigma))$$\n\nThis also translates directly into Python code!\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndef model_log_prob(mu, sigma, y):\n    # log-probability of mu under prior.\n    normal_prior = Normal(0, 10)\n    mu_log_prob = normal_prior.logpdf(mu)\n\n    # log-probability of sigma under prior.\n    sigma_prior = Exponential(1)\n    sigma_log_prob = sigma_prior.logpdf(sigma)\n\n    # log-likelihood given priors and data\n    likelihood = Normal(mu, sigma)\n    likelihood_log_prob = likelihood.logpdf(y).sum()\n\n    # Joint log-likelihood\n    return mu_log_prob + sigma_log_prob + likelihood_log_prob\n```\n:::\n\n\n## Computing the Posterior with Sampling\n\nTo identify what the values of $\\mu$ and $\\sigma$\nshould take on given the data and priors,\nwe can turn to sampling to help us.\nI am intentionally skipping over integrals\nwhich are used to compute expectations,\nwhich is what sampling is replacing.\n\n### Metropolis-Hastings Sampling\n\nAn easy-to-understand sampler that we can start with\nis the Metropolis-Hastings sampler.\nI first learned it in a grad-level computational biology class,\nbut I expect most statistics undergrads should have\na good working knowledge of the algorithm.\n\nFor the rest of us, check out the note below on how the algorithm works.\n\n::: {.callout-note}\n## The Metropolis-Hastings Algorithm\n\nShamelessly copied (and modified)\nfrom the [Wikipedia article][mh]:\n\n- For each parameter $p$, do the following.\n- Initialize an arbitrary point for the parameter (this is $p_t$, or $p$ at step $t$).\n- Define a probability density $P(p_t)$, for which we will draw new values of the parameters. Here, we will use $P(p) = Normal(p_{t-1}, 1)$.\n- For each iteration:\n    - Generate candidate new candidate $p_t$ drawn from $P(p_t)$.\n    - Calculate the likelihood of the data under the previous parameter value(s) $p_{t-1}$: $L(p_{t-1})$\n    - Calculate the likelihood of the data under the proposed parameter value(s) $p_t$: $L(p_t)$\n    - Calculate acceptance ratio $r = \\frac{L(p_t)}{L(p_{t-1})}$.\n    - Generate a new random number on the unit interval: $s \\sim U(0, 1)$.\n    - Compare $s$ to $r$.\n        - If $s \\leq r$, accept $p_t$.\n        - If $s \\gt r$, reject $p_t$ and continue sampling again with $p_{t-1}$.\n\n[mh]: https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm\n:::\n\nIn the algorithm described in the note above,\nour parameters $p$ are $(\\mu, \\sigma)$,\nwhich means we have to propose two numbers\nand sample two numbers in each loop of the sampler.\n\nTo make things simple for us, let's use the normal distribution\ncentered on $0$ but with scale $0.1$\nto propose values for each.\n\nWe can implement the algorithm in Python code:\n\n```python\n# Metropolis-Hastings Sampling\nmu_prev = np.random.normal()\nsigma_prev = np.random.normal()\n\n# Keep a history of the parameter values and ratio.\nmu_history = dict()\nsigma_history = dict()\nratio_history = dict()\n\nfor i in range(1000):\n    mu_history[i] = mu_prev\n    sigma_history[i] = sigma_prev\n    mu_t = np.random.normal(mu_prev, 0.1)\n    sigma_t = np.random.normal(sigma_prev, 0.1)\n\n    # Compute joint log-likelihood\n    LL_t = model_log_prob(mu_t, sigma_t, y)\n    LL_prev = model_log_prob(mu_prev, sigma_prev, y)\n\n    # Calculate the difference in log-likelihoods\n    # (or a.k.a. ratio of likelihoods)\n    diff_log_like = LL_t - LL_prev\n    if diff_log_like > 0:\n        ratio = 1\n    else:\n        # We need to exponentiate to get the correct ratio,\n        # since all of our calculations were in log-space\n        ratio = np.exp(diff_log_like)\n\n    # Defensive programming check\n    if np.isinf(ratio) or np.isnan(ratio):\n        raise ValueError(f\"LL_t: {LL_t}, LL_prev: {LL_prev}\")\n\n    # Ratio comparison step\n    ratio_history[i] = ratio\n    p = np.random.uniform(0, 1)\n\n    if ratio >= p:\n        mu_prev = mu_t\n        sigma_prev = sigma_t\n```\n\nBecause of a desire for convenience,\nwe chose to use a single normal distribution to sample all values.\nHowever, that distribution choice is going to bite us during sampling,\nbecause the values that we could sample for the $\\sigma$ parameter\ncan take on negatives,\nbut when a negative $\\sigma$ is passed\ninto the normally-distributed likelihood,\nwe are going to get computation errors!\nThis is because the scale parameter of a normal distribution\ncan only be positive and cannot be negative or zero.\n(If it were zero, there would be no randomness.)\n\n### Transformations as a Hack\n\nThe critical problem here is that the support of the Exponential distribution\nis bound to be positive real numbers only.\nThat said, we can get around this problem\nsimply by sampling amongst the unbounded real number space $(-\\inf, +\\inf)$,\nand then transform the number by a math function to be in the bounded space.\n\nOne way we can transform numbers from an unbounded space\nto a positive-bounded space\nis to use the exponential transform:\n\n$$y = e^x$$\n\nFor any given value $x$, $y$ will be guaranteed to be positive.\n\nKnowing this, we can modify our sampling code:\n\n```python\n# Initialize in unconstrained space\nsigma_prev_unbounded = np.random.normal(0, 1)\n# ...\nfor i in range(1000):\n    # ...\n    # Propose in unconstrained space\n    sigma_t_unbounded = np.random.normal(sigma_prev_unbounded, 0.1)\n\n    # Transform the sampled values to the constrained space\n    sigma_prev = np.exp(sigma_prev_unbounded)\n    sigma_t = np.exp(sigma_t_unbounded)\n\n    # ...\n\n    # Pass the transformed values into the log-likelihood calculation\n    LL_t = model_log_prob(mu_t, sigma_t, y)\n    LL_prev = model_log_prob(mu_prev, sigma_prev, y)\n\n    # ...\n```\n\nAnd _voila_!\nThe fundamental trick here was\nto **sample in unbounded space** but **evaluate log-likelihood in bounded space**.\nWe call the \"unbounded\" space the _transformed_ space,\nwhile the \"bounded\" space is the _original_ or _untransformed_ space.\nWe have implemented the necessary components\nto compute posterior distributions on parameters!\n\n### Samples from Posterior\n\nIf we simulate 1000 data points from a $Normal(3, 1)$ distribution,\nand pass them into the model log probability function defined above,\nthen after running the sampler,\nwe get a chain of values that the sampler has picked out\nas maximizing the joint likelihood of the data and the model.\nBy the way, this is essentially the simplest version of\nMarkov Chain Monte Carlo sampling that exists\nin modern computational Bayesian statistics.\n\nLet's examine the trace from one run:\n\n![](./comp-bayes-figures/mcmc-trace.png)\n\nNotice how it takes about 200 steps before the trace becomes **stationary**,\nthat is, it becomes a flat trend line.\nIf we prune the trace to just the values after the 200th iteration,\nwe get the following trace:\n\n![](./comp-bayes-figures/mcmc-trace-burn-in.png)\n\nThe samples drawn are an approximation to the expected values of $\\mu$ and $\\sigma$\ngiven the data and priors specified.\n\n::: {.callout-note}\n## Random Variables and Sampling\n\nA piece of wisdom directly quoted from my friend [Colin Carroll][colin],\nwho is also a PyMC developer:\n\n> Random variables are *measures*\n> and measures are only really defined under an integral sign.\n> *Sampling* is usually defined as generating data\n> according to a certain measure.\n> This becomes confusing because we invert this relationship\n> when we do computational statistics:\n> we generate the data,\n> and use that to approximate an integral or expectation.\n:::\n\n## Topics We Skipped Over\n\nWe intentionally skipped over several things here.\n\nOne of them was why we used a normal distribution with a scale of 0.1\nto propose a new value rather than a different scale.\nAs it turns out, the scale parameter is a tunable hyperparameter,\nand in PyMC we do tuning on this hyperparameter when sampling as well.\nIf you want to learn more about how tuning happens,\n[Colin][colin] has a [great essay][tuning] on that too.\n\n[tuning]: https://colcarroll.github.io/hmc_tuning_talk/\n\nWe also skipped over API design,\nas that is a topic I will be exploring in a separate essay.\nIt will also serve as a tour through the PyMC API, as I understand it.\n\n## An Anchoring Thought Framework for Learning Computational Bayes\n\nHaving gone through this exercise\nhas been extremely helpful in deciphering\nwhat goes on behind the scenes in PyMC.\n\nFrom digging through everything from scratch,\nmy thought framework to think about Bayesian modeling\nhas been updated (pun intended) to the following.\n\nFirstly, we can view a Bayesian model\nfrom the axis of **prior, likelihood, posterior**.\nBayes' rule provides us with the equation \"glue\"\nthat links those three components together.\n\nSecondly, when doing _computational_ Bayesian statistics,\nwe should be able to modularly separate **sampling**\nfrom **model definition**.\n**Sampling** is computing the posterior distribution of parameters\ngiven the model and data.\n**Model definition**, by contrast,\nis all about providing the model structure\nas well as a function that calculates the joint log-likelihood\nof the model and data.\n\nBased on the exercise above,\nany \"sampler\" is only concerned with the model log probability\n(though some also require the local gradient of the log probability\nw.r.t. the parameters to find where to climb next),\nand should only be required to accept a **model log probability** function\nand a proposed set of initial parameter values,\nand return a chain of sampled values.\n\nFinally, I hope the _simplest complex example_\nof estimating $\\mu$ and $\\sigma$ of a normal distribution\nhelps further your understanding of the math behind Bayesian statistics.\n\nAll in all, I hope this essay helps your learning, as writing it did for me!\n\n",
    "supporting": [
      "computational-bayesian-stats_files"
    ],
    "filters": [],
    "includes": {}
  }
}
