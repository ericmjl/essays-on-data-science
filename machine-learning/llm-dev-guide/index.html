
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../graph-nets/">
      
      
        <link rel="next" href="../../miscellaneous/dashboarding-landscape/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.2.8">
    
    
      
        <title>A Developer-First Guide to LLM APIs - Essays on Data Science</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.046329b4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.85d0ee34.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/mermaid@7.1.2/dist/mermaid.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#a-developer-first-guide-to-llm-apis-march-2023" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Essays on Data Science" class="md-header__button md-logo" aria-label="Essays on Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Essays on Data Science
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              A Developer-First Guide to LLM APIs
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ericmjl/essays-on-data-science" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Essays on Data Science" class="md-nav__button md-logo" aria-label="Essays on Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Essays on Data Science
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ericmjl/essays-on-data-science" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Computing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Computing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../computing/recursion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recursion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Machine Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../computational-bayesian-stats/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Introduction to Probability and Computational Bayesian Statistics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../markov-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markov Models From The Bottom Up, with Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../generating-markov-chains-dirichlet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dirichlet Processes and Hidden Markov Model Transition Matrices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../message-passing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Computational Representations of Message Passing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../reimplementing-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reimplementing and Testing Deep Learning Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../differential-computing-jax/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Differential Computing Explained
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../nngp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Infinitely Wide Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../graph-nets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Attempt at Demystifying Graph Deep Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    A Developer-First Guide to LLM APIs
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    A Developer-First Guide to LLM APIs
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-problem" class="md-nav__link">
    The Problem
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#desiderata" class="md-nav__link">
    Desiderata
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-test-blog-post" class="md-nav__link">
    The test blog post
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompts" class="md-nav__link">
    Prompts
  </a>
  
    <nav class="md-nav" aria-label="Prompts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post-prompt" class="md-nav__link">
    LinkedIn Post Prompt
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#title-prompt" class="md-nav__link">
    Title Prompt
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setup-api-key" class="md-nav__link">
    Setup API key
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-using-openais-api" class="md-nav__link">
    Implementation using OpenAI's API
  </a>
  
    <nav class="md-nav" aria-label="Implementation using OpenAI's API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summarization" class="md-nav__link">
    Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post" class="md-nav__link">
    LinkedIn Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost-accounting" class="md-nav__link">
    Cost Accounting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-using-langchains-api" class="md-nav__link">
    Implementation using LangChain's API
  </a>
  
    <nav class="md-nav" aria-label="Implementation using LangChain's API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summarization_1" class="md-nav__link">
    Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post_1" class="md-nav__link">
    LinkedIn Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost-accounting_1" class="md-nav__link">
    Cost Accounting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-using-llamaindex" class="md-nav__link">
    Implementation using LlamaIndex
  </a>
  
    <nav class="md-nav" aria-label="Implementation using LlamaIndex">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-text" class="md-nav__link">
    Embed Text
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summarization_2" class="md-nav__link">
    Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post-generation" class="md-nav__link">
    LinkedIn Post Generation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost-accounting_2" class="md-nav__link">
    Cost Accounting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generated-text-comparison" class="md-nav__link">
    Generated Text Comparison
  </a>
  
    <nav class="md-nav" aria-label="Generated Text Comparison">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summarization_3" class="md-nav__link">
    Summarization
  </a>
  
    <nav class="md-nav" aria-label="Summarization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openais-summarization" class="md-nav__link">
    OpenAI's Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langchains-summarization" class="md-nav__link">
    LangChain's Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamaindexs-summarization" class="md-nav__link">
    LlamaIndex's Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#style-verdict" class="md-nav__link">
    Style verdict
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post-generation_1" class="md-nav__link">
    LinkedIn Post Generation
  </a>
  
    <nav class="md-nav" aria-label="LinkedIn Post Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openais-post" class="md-nav__link">
    OpenAI's Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langchains-post" class="md-nav__link">
    LangChain's Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamaindexs-post" class="md-nav__link">
    LlamaIndex's Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#style-verdict_1" class="md-nav__link">
    Style Verdict
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#developer-experience-dx" class="md-nav__link">
    Developer Experience (DX)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#caveats-to-this-analysis" class="md-nav__link">
    Caveats to this analysis
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Miscellaneous
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Miscellaneous
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/dashboarding-landscape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Review of the Python Data Science Dashboarding Landscape in 2019
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/learning-to-learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How I Learned to Learn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/pydata-landscape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Opinionated and Unofficial Guide to the PyData Ecosystem
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/static-sites-on-dokku/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Static Sites and Apps On Your Own Dokku Server
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/code-style-tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Style Tools
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Skills
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Software Skills
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Importance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/code-formatting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Formatting your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/documentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documenting your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/environment-variables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Data Scientist's Guide to Environment Variables
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/refactoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Refactoring your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/testing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Testing your code
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    People Skills
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            People Skills
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../people-skills/hiring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hiring and Interviewing Data Scientists
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Terminal Hacks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Terminal Hacks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../terminal/cli-tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tools and Upgrades for your CLI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../terminal/pre-commits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using pre-commit git hooks to automate code checks
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Workflow
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Workflow
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/code-review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Practicing Code Review
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/effective-commit-messages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Effective Git Commits in Data Science
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/gitflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Principled Git-based Workflow in Collaborative Data Science Projects
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../supporters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supporters
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-problem" class="md-nav__link">
    The Problem
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#desiderata" class="md-nav__link">
    Desiderata
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-test-blog-post" class="md-nav__link">
    The test blog post
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompts" class="md-nav__link">
    Prompts
  </a>
  
    <nav class="md-nav" aria-label="Prompts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post-prompt" class="md-nav__link">
    LinkedIn Post Prompt
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#title-prompt" class="md-nav__link">
    Title Prompt
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setup-api-key" class="md-nav__link">
    Setup API key
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-using-openais-api" class="md-nav__link">
    Implementation using OpenAI's API
  </a>
  
    <nav class="md-nav" aria-label="Implementation using OpenAI's API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summarization" class="md-nav__link">
    Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post" class="md-nav__link">
    LinkedIn Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost-accounting" class="md-nav__link">
    Cost Accounting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-using-langchains-api" class="md-nav__link">
    Implementation using LangChain's API
  </a>
  
    <nav class="md-nav" aria-label="Implementation using LangChain's API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summarization_1" class="md-nav__link">
    Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post_1" class="md-nav__link">
    LinkedIn Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost-accounting_1" class="md-nav__link">
    Cost Accounting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-using-llamaindex" class="md-nav__link">
    Implementation using LlamaIndex
  </a>
  
    <nav class="md-nav" aria-label="Implementation using LlamaIndex">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#embed-text" class="md-nav__link">
    Embed Text
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summarization_2" class="md-nav__link">
    Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post-generation" class="md-nav__link">
    LinkedIn Post Generation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cost-accounting_2" class="md-nav__link">
    Cost Accounting
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generated-text-comparison" class="md-nav__link">
    Generated Text Comparison
  </a>
  
    <nav class="md-nav" aria-label="Generated Text Comparison">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summarization_3" class="md-nav__link">
    Summarization
  </a>
  
    <nav class="md-nav" aria-label="Summarization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openais-summarization" class="md-nav__link">
    OpenAI's Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langchains-summarization" class="md-nav__link">
    LangChain's Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamaindexs-summarization" class="md-nav__link">
    LlamaIndex's Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#style-verdict" class="md-nav__link">
    Style verdict
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkedin-post-generation_1" class="md-nav__link">
    LinkedIn Post Generation
  </a>
  
    <nav class="md-nav" aria-label="LinkedIn Post Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openais-post" class="md-nav__link">
    OpenAI's Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langchains-post" class="md-nav__link">
    LangChain's Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamaindexs-post" class="md-nav__link">
    LlamaIndex's Post
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#style-verdict_1" class="md-nav__link">
    Style Verdict
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#developer-experience-dx" class="md-nav__link">
    Developer Experience (DX)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#caveats-to-this-analysis" class="md-nav__link">
    Caveats to this analysis
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="a-developer-first-guide-to-llm-apis-march-2023">A Developer-First Guide to LLM APIs (March 2023)</h1>
<p>Large Language Models (LLMs) are having a moment now!
We can interact with them programmatically in three ways:
OpenAI's official API,
LangChain's abstractions,
and LlamaIndex.
How do we choose among the three?
I'd like to use a minimally complex example to showcase how we might make this decision.</p>
<h2 id="the-problem">The Problem</h2>
<p>I blog.</p>
<p>(Ok, well, that's quite the understatement, given that you're reading it right now.)</p>
<p>As you probably can tell from my blog's design,
I need to summarize the blog post for the blog landing page.
Because I usually share the post on LinkedIn,
I also need to generate a LinkedIn post advertising the blog post.
I've heard that emojis are great when sharing posts on LinkedIn,
but I can only sometimes remember the names of appropriate emojis.
Some automation help would be great here.
Finally, if I can make a better title than I initially thought of,
that would also constitute an improvement.</p>
<p>I've decided that I wanted a tool that can summarize my blog posts,
generate appropriately emojified LinkedIn posts for me to advertise those posts,
and provide a catchy and engaging title without being clickbait.
These are tedious to write!
Wouldn't it be great to have a tool that can generate both?
That's the use case for LLMs!</p>
<h2 id="desiderata">Desiderata</h2>
<p>Here's the list of requirements I have to build the tool I want.</p>
<p>Firstly, I should be able to provide the <em>text</em> of a blog post as input and get back:</p>
<ol>
<li>A proposed title according to my desired specifications,</li>
<li>A summary to put onto my website's blog listing page, and</li>
<li>A LinkedIn post that I can use to share with others.</li>
</ol>
<p>Secondly, the tool should minimize token usage.
Tokens equal money spent on this task,
so saving on token usage would increase my leverage trading time for money.</p>
<p>Finally, because I'm still writing some code to implement this tool,
I'd like to use a package that would provide the most easily maintained code.
Of course, that means a subjective judgment of how simple the abstractions are.</p>
<p>To that end, I will show how to implement this writing tool using three APIs currently available:
the official OpenAI Python API, the LangChain API, and the LlamaIndex API.
This exercise lets us see which ones are most suitable for this particular use case.
We will be using GPT-4 everywhere, as its quality is known to be superior to GPT-3.5.
Finally, I will focus on blog post summary generation and LinkedIn post generation
when comparing the APIs before choosing one framework to implement the complete program.</p>
<h2 id="the-test-blog-post">The test blog post</h2>
<p>The blog post I'll use for implementing this is my most recent one on the Arc browser.
I will be passing in the Lektor raw source without the title.
The raw source is available on <a href="https://raw.githubusercontent.com/ericmjl/website/main/content/blog/arc-browser-first-impressions/contents.lr">my website repository</a>.</p>
<p>According to <a href="https://github.com/openai/tiktoken"><code>tiktoken</code></a>,
this text uses 1436 tokens to encode:</p>
<div class="highlight"><pre><span></span><code><span class="n">blog_text</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># taken from my raw source.</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&quot;cl100k_base&quot;</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">blog_text</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>1436
</code></pre></div>
<p>This is a constant throughout the post.</p>
<h2 id="prompts">Prompts</h2>
<p>The prompts that I will use to generate the desired text are as follows.
If the three prompts are too long to remember,
you can focus on the one for summarization as an anchoring example.</p>
<h3 id="summary">Summary</h3>
<div class="highlight"><pre><span></span><code><span class="n">summarization_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;You are a blog post summarization bot.</span>
<span class="s2">Your take a blog post and write a summary of it.</span>
<span class="s2">The summary is intended to hook a reader into the blog post and entice them to read it.</span>
<span class="s2">You should add in emojis where appropriate.</span>

<span class="s2">My previous summaries sounded like this:</span>

<span class="s2">1. I finally figured out how to programmatically create Google Docs using Python. Along the way, I figured out service accounts, special HTML tags, and how to set multi-line environment variables. Does that tickle your brain?</span>
<span class="s2">2. Here is my personal experience creating an app for translating Ark Channel devotionals using OpenAI&#39;s GPT-3. In here, I write about the challenges I faced and the lessons I learned! I hope it is informative for you!</span>
<span class="s2">3. I discuss two Twitter threads that outline potential business ideas that could be built on top of ChatGPT3, a chatbot-based language model. What&#39;s the tl;dr? As mankind has done over and over, we build machines to solve mundane and repetitive tasks, and ChatGPT3 and other generative models are no exception!</span>

<span class="s2">The summary you generate should match the tone and style of the previously-generated ones.</span>
<span class="s2">&quot;&quot;&quot;</span>
</code></pre></div>
<h3 id="linkedin-post-prompt">LinkedIn Post Prompt</h3>
<div class="highlight"><pre><span></span><code><span class="n">linkedin_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are a LinkedIn post generator bot.</span>
<span class="s2">You take a blog post and write a LinkedIn post.</span>
<span class="s2">The post is intended to hook a reader into reading the blog post.</span>
<span class="s2">The LinkedIn post should be written with one line per sentence.</span>
<span class="s2">Each sentence should begin with an emoji appropriate to that sentence.</span>
<span class="s2">The post should be written in professional English and in first-person tone.</span>
<span class="s2">&quot;&quot;&quot;</span>
</code></pre></div>
<h3 id="title-prompt">Title Prompt</h3>
<div class="highlight"><pre><span></span><code><span class="n">title_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are a blog post title generator.</span>
<span class="s2">You take a blog post and write a title for it.</span>
<span class="s2">The title should be short, ideally less than 100 characters.</span>
<span class="s2">It should be catchy but not click-baity,</span>
<span class="s2">free from emojis, and should intrigue readers,</span>
<span class="s2">making them want to read the summary and the post itself.</span>
<span class="s2">Ensure that the title accurately captures</span>
<span class="s2">the contents of the post.</span>
<span class="s2">&quot;&quot;&quot;</span>
</code></pre></div>
<h2 id="setup-api-key">Setup API key</h2>
<p>Using OpenAI‚Äôs API requires we set the OpenAI API key before doing anything;
this is also true for using LangChain and LlamaIndex.
As always, to adhere to reasonable security practices when developing locally,
we should store the API key as an environment variable in a <code>.env</code> file
listed in the <code>.gitignore</code>of a repository
and then load the API key in our Jupyter notebooks.
Here is how we implement it. Firstly, the <code>.env</code> file:</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="c1"># .env</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">OPENAI_API_KEY</span><span class="o">=</span><span class="s2">&quot;...&quot;</span>
</code></pre></div>
<p>And then, at the top of our Jupyter notebook or Python script:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">import</span> <span class="nn">openai</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">load_dotenv</span><span class="p">()</span>

<span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">)</span>
</code></pre></div>
<h2 id="implementation-using-openais-api">Implementation using OpenAI's API</h2>
<h3 id="summarization">Summarization</h3>
<p>Let‚Äôs start off using the OpenAI Python API. To use GPT-4, we need to provide a chat history of messages that looks something like this:</p>
<div class="highlight"><pre><span></span><code><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">summarization_prompt</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Here is my blog post source: </span><span class="si">{</span><span class="n">blog_post</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">]</span>
</code></pre></div>
<p>Then, we pass the message history into the OpenAI chat completion class</p>
<div class="highlight"><pre><span></span><code><span class="n">result</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</code></pre></div>
<p>Once the API call has returned, we can see what gets returned:</p>
<div class="highlight"><pre><span></span><code><span class="n">summary</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>I recently got my hands on the new [Arc browser](https://arc.net/) and I&#39;m loving it! ü§© Arc reimagines the browser as a workspace, helping us manage our chaotic tabs and multiple projects. Some cool features include tabs that expire ‚è≥, spaces for grouping tabs üóÇÔ∏è, rapid switching between tabbed and full-screen mode üñ•Ô∏è, side-by-side view for multitasking üìë, and automatic developer mode for locally hosted sites üîß. Arc&#39;s focus on UI design is a game-changer for productivity and focus! Check out my first impressions and see if Arc could be your new favorite browser! üöÄ
</code></pre></div>
<p>The total number of tokens used here is:</p>
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">summarization_prompt</span><span class="p">))</span> \
<span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">human_message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]))</span> \
<span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">summary</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>1870
</code></pre></div>
<h3 id="linkedin-post">LinkedIn Post</h3>
<p>Now, let's make the LinkedIn post.</p>
<div class="highlight"><pre><span></span><code><span class="n">linkedin_prompt</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">linkedin_prompt</span><span class="p">}</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">linkedin_prompt</span><span class="p">,</span> <span class="n">human_message</span><span class="p">]</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="n">linkedin_post</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linkedin_post</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>üöÄ Just tried the new [Arc browser](https://arc.net/) for 24 hours!

üß† It&#39;s designed to fit the modern multitasker&#39;s brain.

‚è≥ Love the tabs that expire feature - goodbye clutter!

üåê Spaces for grouping tabs - perfect for juggling multiple projects.

üîç Rapid switching between tabbed and full-screen mode for better focus.

üìè Side-by-side view for efficient multitasking.

üë®‚Äçüíª Automatic developer mode for locally hosted sites - a developer&#39;s dream!

üåü Overall, Arc is a game-changer for productivity and focus.

üìñ Read my full experience in the blog post [here](&lt;blog_post_link&gt;).
</code></pre></div>
<p>The total number of tokens used here is:</p>
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">linkedin_prompt</span><span class="p">))</span> \
<span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">human_message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]))</span> \
<span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">linkedin_post</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>1669
</code></pre></div>
<h3 id="cost-accounting">Cost Accounting</h3>
<p>Tabulating the total cost of tokens,
we have 3c per 1,000 tokens for prompts
and 6c per 1,000 token for generated texts.
We can do the math easily here:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Cost</span>
<span class="n">prompt_encoding_lengths</span> <span class="o">=</span> <span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">linkedin_prompt</span><span class="p">))</span> \
    <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">human_message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]))</span> \
    <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">summarization_prompt</span><span class="p">))</span> \
    <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">human_message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]))</span>
<span class="p">)</span>

<span class="n">generated_encoding_lengths</span> <span class="o">=</span> <span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">linkedin_post</span><span class="p">))</span> <span class="o">+</span> \
    <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">summary</span><span class="p">))</span>
<span class="p">)</span>

<span class="n">cost</span> <span class="o">=</span> <span class="p">(</span>
    <span class="mf">0.03</span> <span class="o">*</span> <span class="n">prompt_encoding_lengths</span> <span class="o">+</span> <span class="mf">0.06</span> <span class="o">*</span> <span class="n">generated_encoding_lengths</span>
<span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="mf">0.11657999999999999</span>
</code></pre></div>
<p>Or about 12c to perform this operation.</p>
<p>How much ROI do we get here?
Excluding benefits, equity, and more, a new Ph.D. grad data scientist
is paid about <code>$150,000</code> (give or take) per year in the biomedical industry in 2023.
Assuming about 250 days of work per year at an average of 8 hours per day,
we're talking about an hourly rate of <code>$75</code>/hr at that salary.
If it takes that person 10 minutes to cook up a summary and LinkedIn post
(which is about how long I take -
excluding figuring out what emojis to put in
because that's, for me, bloody time-consuming.),
then we're looking at <code>$12.5</code> worth of time put into crafting that post.
Looking at just the cold hard numbers,
<strong>we're looking at a 100X cost improvement by using GPT-4 as a writing aid.</strong></p>
<h2 id="implementation-using-langchains-api">Implementation using LangChain's API</h2>
<p>Now, let's do the same thing, except with the LangChain API. Here, we'll be using LangChain's Chain API.</p>
<h3 id="summarization_1">Summarization</h3>
<p>First off, summarization:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="nn">langchain.prompts.chat</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="p">,</span>
    <span class="n">HumanMessagePromptTemplate</span><span class="p">,</span>
    <span class="n">SystemMessagePromptTemplate</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="n">system_message_prompt</span> <span class="o">=</span> <span class="n">SystemMessagePromptTemplate</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">PromptTemplate</span><span class="p">(</span>
        <span class="n">template</span><span class="o">=</span><span class="n">summarization_prompt</span><span class="p">,</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[],</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>


<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="n">human_message_prompt</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">PromptTemplate</span><span class="p">(</span>
        <span class="n">template</span><span class="o">=</span><span class="s2">&quot;Here is my post:</span><span class="se">\n\n</span><span class="s2"> </span><span class="si">{blog_post}</span><span class="s2">?&quot;</span><span class="p">,</span>
        <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;blog_post&quot;</span><span class="p">],</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">chat_prompt_template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span><span class="n">system_message_prompt</span><span class="p">,</span> <span class="n">human_message_prompt</span><span class="p">])</span>
<span class="n">summary_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">chat</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">chat_prompt_template</span><span class="p">)</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">summary_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">blog_post</span><span class="o">=</span><span class="n">blog_text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>I recently tried out the Arc browser üåê, which reimagines the browser as a workspace to boost productivity! üöÄ After 24 hours of use, I&#39;m loving its features: tabs that expire ‚è≥, spaces for organizing tabs üóÇÔ∏è, rapid switching between tabbed and full-screen mode üñ•Ô∏è, side-by-side view for multitasking üìë, and automatic developer mode for locally hosted sites üíª. Arc&#39;s focus on UI design helps us stay focused and organized in our digital lives. Curious to know more? Dive into my first impressions! üòÉ
</code></pre></div>
<p>According to tiktoken:</p>
<div class="highlight"><pre><span></span><code>len(encoder.encode(summary))
</code></pre></div>
<p>The generated text was 191 tokens.
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">system_message_prompt</span><span class="o">.</span><span class="n">format_messages</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
</code></pre></div></p>
<p>The system prompt was 237 tokens.</p>
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">human_message_prompt</span><span class="o">.</span><span class="n">format_messages</span><span class="p">(</span><span class="n">blog_post</span><span class="o">=</span><span class="n">blog_text</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
</code></pre></div>
<p>The human message prompt was 1442.</p>
<p>We'll keep those numbers in mind when doing the final cost accounting.</p>
<h3 id="linkedin-post_1">LinkedIn Post</h3>
<p>Now, let's make the LinkedIn post.</p>
<div class="highlight"><pre><span></span><code><span class="n">linkedin_system_prompt</span> <span class="o">=</span> <span class="n">SystemMessagePromptTemplate</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">PromptTemplate</span><span class="p">(</span>
        <span class="n">template</span><span class="o">=</span><span class="n">linkedin_prompt</span><span class="p">,</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[],</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">linkedin_blog_prompt</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">PromptTemplate</span><span class="p">(</span>
        <span class="n">template</span><span class="o">=</span><span class="s2">&quot;Here is the blog post:</span><span class="se">\n\n</span><span class="si">{blog_post}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;blog_post&quot;</span><span class="p">],</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">linkedin_chat_prompt_template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span><span class="n">linkedin_system_prompt</span><span class="p">,</span> <span class="n">linkedin_blog_prompt</span><span class="p">])</span>

<span class="n">linkedin_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">chat</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">linkedin_chat_prompt_template</span><span class="p">)</span>

<span class="n">linkedin_post</span> <span class="o">=</span> <span class="n">linkedin_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">blog_post</span><span class="o">=</span><span class="n">blog_text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linkedin_post</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>üéâ Just tried the new [Arc browser](https://arc.net/) and I&#39;m loving it! üß†

üïí Arc&#39;s unique features like tabs that expire and spaces for different projects help me stay focused and organized. üìå

üöÄ Check out my blog post for a detailed review and first impressions of this game-changing browser: [Arc Browser: First Impressions](&lt;blog post link&gt;) üåê

üë®‚Äçüíª Are you ready to revolutionize your browsing experience? #ArcBrowser #Productivity #Tools
</code></pre></div>
<p>Doing an accounting of the tokens once again:</p>
<div class="highlight"><pre><span></span><code>len(encoder.encode(linkedin_post))
</code></pre></div>
<p>The generated LinkedIn post used 151 generated tokens.</p>
<div class="highlight"><pre><span></span><code>len(encoder.encode(linkedin_blog_prompt.format_messages(blog_post=blog_text)[0].content))
</code></pre></div>
<p>The blog post prompt itself used 1441 prompt tokens.</p>
<div class="highlight"><pre><span></span><code>len(encoder.encode(linkedin_system_prompt.format_messages()[0].content))
</code></pre></div>
<p>And the system prompt used 71 tokens.</p>
<h3 id="cost-accounting_1">Cost Accounting</h3>
<p>As usual, let's do the accounting of tokens.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Cost Accounting</span>
<span class="n">generated_encodings_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">linkedin_post</span><span class="p">))</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">summary</span><span class="p">))</span>

<span class="n">prompt_lengths</span> <span class="o">=</span> <span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">human_message_prompt</span><span class="o">.</span><span class="n">format_messages</span><span class="p">(</span><span class="n">blog_post</span><span class="o">=</span><span class="n">blog_text</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">))</span> \
    <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">system_message_prompt</span><span class="o">.</span><span class="n">format_messages</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">))</span> \
    <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">linkedin_blog_prompt</span><span class="o">.</span><span class="n">format_messages</span><span class="p">(</span><span class="n">blog_post</span><span class="o">=</span><span class="n">blog_text</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">))</span> \
    <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">linkedin_system_prompt</span><span class="o">.</span><span class="n">format_messages</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
<span class="p">)</span>

<span class="n">cost</span> <span class="o">=</span> <span class="mf">0.03</span> <span class="o">*</span> <span class="n">prompt_lengths</span> <span class="o">+</span> <span class="mf">0.06</span> <span class="o">*</span> <span class="n">generated_encodings_length</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cost</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="mf">0.11648999999999998</span>
</code></pre></div>
<p>As we can see, this also costs about 12c for the entire exercise.</p>
<h2 id="implementation-using-llamaindex">Implementation using LlamaIndex</h2>
<p>The way LlamaIndex works is different from the previous two frameworks.
With OpenAI's and LangChain's APIs, we stuffed the entire document into the prompt for each task.
With LlamaIndex, we can embed and store the text beforehand
and then query it with a prompt for our LLM. Here is how it looks:</p>
<h3 id="embed-text">Embed Text</h3>
<p>To do this, we use the <code>GPTSimpleVectorIndex</code> provided by LlamaIndex:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">llama_index</span> <span class="kn">import</span> <span class="n">Document</span><span class="p">,</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">,</span> <span class="n">LLMPredictor</span>

<span class="c1"># Index documents using GPT4</span>
<span class="n">llm_predictor</span> <span class="o">=</span> <span class="n">LLMPredictor</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">chat</span><span class="p">)</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">Document</span><span class="p">(</span><span class="n">blog_text</span><span class="p">)]</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">GPTSimpleVectorIndex</span><span class="p">(</span><span class="n">documents</span><span class="o">=</span><span class="n">documents</span><span class="p">,</span> <span class="n">llm_predictor</span><span class="o">=</span><span class="n">llm_predictor</span><span class="p">)</span>
</code></pre></div>
<p>Thanks to the built-in token accounting capabilities of LlamaIndex, we can see that building the index costed us 1637 tokens.</p>
<div class="highlight"><pre><span></span><code>INFO:llama_index.token_counter.token_counter:&gt; [build_index_from_documents] Total LLM token usage: 0 tokens
INFO:llama_index.token_counter.token_counter:&gt; [build_index_from_documents] Total embedding token usage: 1637 tokens
</code></pre></div>
<h3 id="summarization_2">Summarization</h3>
<p>Let's start by creating a summary of the blog post.</p>
<div class="highlight"><pre><span></span><code><span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">summarization_prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Discover the Arc browser, a game-changer that reimagines the browser as a workspace üåê! With features like tabs that expire ‚è≥, spaces for grouping tabs üìÅ, rapid switching between modes ‚ö°, side-by-side view üëÄ, and automatic developer mode for locally hosted sites üîß, Arc is designed to boost your productivity and focus üöÄ. Dive into my 24-hour experience with this innovative browser and see how it fits my brain üß†!
</code></pre></div>
<p>Not bad! The response looks pretty good, though I might edit it a bit further.</p>
<p>The token usage here is:</p>
<div class="highlight"><pre><span></span><code>INFO:llama_index.token_counter.token_counter:&gt; [query] Total LLM token usage: 2026 tokens
INFO:llama_index.token_counter.token_counter:&gt; [query] Total embedding token usage: 257 tokens
</code></pre></div>
<h3 id="linkedin-post-generation">LinkedIn Post Generation</h3>
<p>Now, let's try generating a LinkedIn post the same way.</p>
<div class="highlight"><pre><span></span><code><span class="n">response</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">linkedin_prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>üöÄ Just tried the new Arc browser for 24 hours!
üåü It reimagines the browser as a workspace, perfect for multitaskers.
‚è∞ Love the tabs that expire feature, keeping my workspace clutter-free.
üåà Spaces help me group tabs by context, boosting focus and productivity.
üñ•Ô∏è Rapid switching between tabbed and full-screen mode is a game-changer.
üë©‚Äçüíª Developer mode for locally hosted sites makes web development a breeze.
üîó Check out my detailed review on my blog and see how Arc can transform your browsing experience!
</code></pre></div>
<p>Not bad, it followed my instructions as well.</p>
<p>Here's the token usage:</p>
<div class="highlight"><pre><span></span><code>INFO:llama_index.token_counter.token_counter:&gt; [query] Total LLM token usage: 1874 tokens
INFO:llama_index.token_counter.token_counter:&gt; [query] Total embedding token usage: 78 tokens
</code></pre></div>
<h3 id="cost-accounting_2">Cost Accounting</h3>
<p>LlamaIndex did not break down the difference in prompt tokens vs. generated text tokens for me
but split out embedding tokens.
In calculating the cost, we will make the following assumptions:</p>
<ul>
<li>the cost of embedding tokens to be <a href="https://platform.openai.com/docs/guides/embeddings/what-are-embeddings">$0.0004 per 1000 tokens</a>,</li>
<li>of the LLM token usage budget, the part used for prompting can be calculated by subtracting the number of tokens used to encode the output from the reported LLM token usage.</li>
</ul>
<p>Crunching the numbers, we get:</p>
<div class="highlight"><pre><span></span><code><span class="n">embedding_tokens</span> <span class="o">=</span> <span class="mi">1637</span> <span class="o">+</span> <span class="mi">257</span> <span class="o">+</span> <span class="mi">78</span>

<span class="n">linkedin_llm_tokens</span> <span class="o">=</span> <span class="mi">1874</span>
<span class="n">linkedin_generated_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">response</span><span class="p">))</span>

<span class="n">summary_llm_tokens</span> <span class="o">=</span> <span class="mi">2026</span>
<span class="n">summary_generated_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">summary_response</span><span class="o">.</span><span class="n">response</span><span class="p">))</span>

<span class="n">llm_tokens_cost</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.06</span> <span class="o">*</span> <span class="p">(</span><span class="n">linkedin_generated_tokens</span> <span class="o">+</span> <span class="n">summary_generated_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.03</span> <span class="o">*</span> <span class="p">(</span><span class="n">linkedin_llm_tokens</span> <span class="o">-</span> <span class="n">linkedin_generated_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.03</span> <span class="o">*</span> <span class="p">(</span><span class="n">summary_llm_tokens</span> <span class="o">-</span> <span class="n">summary_generated_tokens</span><span class="p">))</span> <span class="o">/</span> <span class="mi">1000</span>

<span class="n">embedding_tokens_cost</span> <span class="o">=</span> <span class="n">embedding_tokens</span> <span class="o">*</span> <span class="mf">0.0004</span> <span class="o">/</span> <span class="mi">1000</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cost: </span><span class="si">{</span><span class="n">llm_tokens_cost</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">embedding_tokens_cost</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Cost: 0.1243588
</code></pre></div>
<p>Also about 12c for this exercise.</p>
<h2 id="generated-text-comparison">Generated Text Comparison</h2>
<h3 id="summarization_3">Summarization</h3>
<p>Here are the generated texts for summarization side-by-side:</p>
<h4 id="openais-summarization">OpenAI's Summarization</h4>
<div class="highlight"><pre><span></span><code>I recently got my hands on the new [Arc browser](https://arc.net/) and I&#39;m loving it! ü§© Arc reimagines the browser as a workspace, helping us manage our chaotic tabs and multiple projects. Some cool features include tabs that expire ‚è≥, spaces for grouping tabs üóÇÔ∏è, rapid switching between tabbed and full-screen mode üñ•Ô∏è, side-by-side view for multitasking üìë, and automatic developer mode for locally hosted sites üîß. Arc&#39;s focus on UI design is a game-changer for productivity and focus! Check out my first impressions and see if Arc could be your new favorite browser! üöÄ
</code></pre></div>
<h4 id="langchains-summarization">LangChain's Summarization</h4>
<div class="highlight"><pre><span></span><code>I recently tried out the Arc browser üåê, which reimagines the browser as a workspace to boost productivity! üöÄ After 24 hours of use, I&#39;m loving its features: tabs that expire ‚è≥, spaces for organizing tabs üóÇÔ∏è, rapid switching between tabbed and full-screen mode üñ•Ô∏è, side-by-side view for multitasking üìë, and automatic developer mode for locally hosted sites üíª. Arc&#39;s focus on UI design helps us stay focused and organized in our digital lives. Curious to know more? Dive into my first impressions! üòÉ
</code></pre></div>
<h4 id="llamaindexs-summarization">LlamaIndex's Summarization</h4>
<div class="highlight"><pre><span></span><code>Discover the Arc browser, a game-changer that reimagines the browser as a workspace üåê! With features like tabs that expire ‚è≥, spaces for grouping tabs üìÅ, rapid switching between modes ‚ö°, side-by-side view üëÄ, and automatic developer mode for locally hosted sites üîß, Arc is designed to boost your productivity and focus üöÄ. Dive into my 24-hour experience with this innovative browser and see how it fits my brain üß†!
</code></pre></div>
<h4 id="style-verdict">Style verdict</h4>
<p>Of the three, LlamaIndex's style is the furthest from my usual style,
though, in some instances, I might choose the style generated by LlamaIndex to change things up on my blog.</p>
<h3 id="linkedin-post-generation_1">LinkedIn Post Generation</h3>
<h4 id="openais-post">OpenAI's Post</h4>
<div class="highlight"><pre><span></span><code>üöÄ Just tried the new [Arc browser](https://arc.net/) for 24 hours!

üß† It&#39;s designed to fit the modern multitasker&#39;s brain.

‚è≥ Love the tabs that expire feature - goodbye clutter!

üåê Spaces for grouping tabs - perfect for juggling multiple projects.

üîç Rapid switching between tabbed and full-screen mode for better focus.

üìè Side-by-side view for efficient multitasking.

üë®‚Äçüíª Automatic developer mode for locally hosted sites - a developer&#39;s dream!

üåü Overall, Arc is a game-changer for productivity and focus.

üìñ Read my full experience in the blog post [here](&lt;blog_post_link&gt;).
</code></pre></div>
<h4 id="langchains-post">LangChain's Post</h4>
<div class="highlight"><pre><span></span><code>üéâ Just tried the new [Arc browser](https://arc.net/) and I&#39;m loving it! üß†

üïí Arc&#39;s unique features like tabs that expire and spaces for different projects help me stay focused and organized. üìå

üöÄ Check out my blog post for a detailed review and first impressions of this game-changing browser: [Arc Browser: First Impressions](&lt;blog post link&gt;) üåê

üë®‚Äçüíª Are you ready to revolutionize your browsing experience? #ArcBrowser #Productivity #Tools
</code></pre></div>
<h4 id="llamaindexs-post">LlamaIndex's Post</h4>
<div class="highlight"><pre><span></span><code>üöÄ Just tried the new Arc browser for 24 hours!
üåü It reimagines the browser as a workspace, perfect for multitaskers.
‚è∞ Love the tabs that expire feature, keeping my workspace clutter-free.
üåà Spaces help me group tabs by context, boosting focus and productivity.
üñ•Ô∏è Rapid switching between tabbed and full-screen mode is a game-changer.
üë©‚Äçüíª Developer mode for locally hosted sites makes web development a breeze.
üîó Check out my detailed review on my blog and see how Arc can transform your browsing experience!
</code></pre></div>
<h4 id="style-verdict_1">Style Verdict</h4>
<p>Of the three, OpenAI's is furthest from how I usually write my LinkedIn posts,
but in fairness, I didn't instruct the model with examples provided.
If I were to choose, I would pick LlamaIndex's generated post.</p>
<h2 id="developer-experience-dx">Developer Experience (DX)</h2>
<p>For this simple use case, which would I go with? LlamaIndex, OpenAI's official API, or LangChain?</p>
<p>As a lazy programmer, I would go with LlamaIndex.
That's because I needed the fewest lines of code to reach my desired endpoints.
It is easy to remember the API as well - you only need to remember the pattern:</p>
<ol>
<li><code>Document</code> to wrap the text that we imported,</li>
<li><code>GPTSimpleVectorIndex</code> (or more generically <code>&lt;some&gt;Index</code>), and</li>
<li><code>LLMPredictor</code> to wrap around LangChain's LLMs.</li>
<li><code>&lt;Index&gt;.query(prompt)</code></li>
</ol>
<p>The biggest reason why LlamaIndex is best suited to this use case is that
querying text is a relatively simple use case.
We only need to load the document in a query-able fashion.
Furthermore, as you can see from my code above,
using LlamaIndex resulted in the least boilerplate code.</p>
<p>That said, is LlamaIndex the right choice for every application?
Probably not.
As of March 2023, LangChain is geared towards much more complex (and autonomous) LLM use cases.
So the abstractions that the library creators put in the library may be geared
to design larger LLM applications rather than simple ones like we just did.
And OpenAI's API is officially supported,
which means it would likely have an official "blessing" in the long run.</p>
<p>I have a penchant/bias for more tightly-controlled LLM applications,
which means forgoing a chat interface in favour of a single-text-in-single-text-out interface.
Indeed, while I see the usefulness of chat-based interfaces for exploration,
I don't think it will become the dominant UI when embedding LLMs in applications.
Rather, I predict that we'll see UI/UX researchers designing, on a per-application basis,
whether to use a free-flowing chat UI or to use a more tightly controlled ad-lib-style interface,
or <a href="https://twitter.com/thesephist/status/1587929014848540673">even</a>
<a href="https://twitter.com/thesephist/status/1592241959489380354">crazier</a>
<a href="https://twitter.com/thesephist/status/1590545448066252800">interfaces</a>!
The factor that should matter the most here is the ROI gained in human time.</p>
<p>Additionally, I predict that we will see data science teams use LLMs
to bang out dozens of little utility apps much faster than previously possible.
These utility apps will likely serve niche-specific but often-repeated use cases,
and may serve as the basis of larger applications that get developed.
For example, we'll probably see built apps that let users ad-lib a templated prompt.
We'll see things like LLMs being the role of data engineer
(e.g. <a href="https://ericmjl.github.io/blog/2023/2/5/building-a-gpt3-based-translation-app/">structuring data from unstructured text</a>)
and domain-specific idea generators prompted by domain experts or domain needs (as we saw here),</p>
<p>The short answer is that we'll see more customization to local contexts,
with highest ROI use cases being prioritized.</p>
<h2 id="caveats-to-this-analysis">Caveats to this analysis</h2>
<p>There are some caveats here to what I've done that I'd like to point out.</p>
<p>Firstly, I've used the most straightforward implementations, stuffing the most text into the prompt.
Why? It is because I'm still exploring the libraries and their APIs and partly because so much development has happened quickly.
Others will be able to figure out more efficient ways of implementing what we did here with their favourite framework.</p>
<p>Secondly, this particular task is quite simple.
LangChain, on the other hand, can generate much more complex programs, as we can see from its documentation.
Critiquing LangChain's heavy abstractions would be unfair, as it's very likely designed for more complex autonomous applications.</p>
<h2 id="conclusion">Conclusion</h2>
<p>One application built three ways with three different libraries.
We have seen how the outputs can differ even with the same prompts and how the developer experience can vary between the three.
That said, I caution that these are early days.
Libraries evolve.
Their developers can introduce more overhead or reduce it.
It's probably too early to "pick a winner";
as far as I can tell, it's less a competition and more a collaboration between these library developers.
However, we can keep abreast of the latest developments and keep experimenting with the libraries on the side,
finding out what works and what doesn't and adapting along the way.</p>
<p>The near-term value proposition of GPT as a tool lies in its ability to automate low-risk, high-effort writing.
We saw through cost calculations that LLMs can represent a 100X ROI in time saved.
For us, as data scientists, that should be heartening!
Where in your day-to-day work can you find a similar 100X ROI?</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="http://www.shortwhale.com/ericmjl" target="_blank" rel="noopener" title="www.shortwhale.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2Z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/ericmjl" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/ericmjl" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://linkedin.com/in/ericmjl" target="_blank" rel="noopener" title="linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["tabs"], "search": "../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.dff1b7c8.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js"></script>
      
    
  </body>
</html>