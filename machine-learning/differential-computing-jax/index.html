
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../reimplementing-models/">
      
      
        <link rel="next" href="../nngp/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.2.8">
    
    
      
        <title>Differential Computing Explained - Essays on Data Science</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.046329b4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.85d0ee34.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/mermaid@7.1.2/dist/mermaid.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#differential-computing-with-jax" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Essays on Data Science" class="md-header__button md-logo" aria-label="Essays on Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Essays on Data Science
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Differential Computing Explained
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ericmjl/essays-on-data-science" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Essays on Data Science" class="md-nav__button md-logo" aria-label="Essays on Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Essays on Data Science
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ericmjl/essays-on-data-science" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Computing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Computing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../computing/recursion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recursion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Machine Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../computational-bayesian-stats/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Introduction to Probability and Computational Bayesian Statistics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../markov-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markov Models From The Bottom Up, with Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../generating-markov-chains-dirichlet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dirichlet Processes and Hidden Markov Model Transition Matrices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../message-passing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Computational Representations of Message Passing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../reimplementing-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reimplementing and Testing Deep Learning Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Differential Computing Explained
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Differential Computing Explained
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#on-differential-computing" class="md-nav__link">
    On differential computing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#where-differential-computing-gets-used" class="md-nav__link">
    Where differential computing gets used
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-landscape-of-ad-systems" class="md-nav__link">
    The landscape of AD systems
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-makes-jax-special" class="md-nav__link">
    What makes JAX special?
  </a>
  
    <nav class="md-nav" aria-label="What makes JAX special?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api-compatible-differentiable-computing" class="md-nav__link">
    API-compatible differentiable computing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api-compatibility-with-the-rest-of-the-pydata-stack" class="md-nav__link">
    API-compatibility with the rest of the PyData stack
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#composable-program-transforms" class="md-nav__link">
    Composable program transforms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-jax-enables-and-doesnt-enable" class="md-nav__link">
    What JAX enables and doesn't enable
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recent-developments" class="md-nav__link">
    Recent developments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-more" class="md-nav__link">
    Learning more
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../nngp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Infinitely Wide Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../graph-nets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Attempt at Demystifying Graph Deep Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../llm-dev-guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Developer-First Guide to LLM APIs
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Miscellaneous
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Miscellaneous
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/dashboarding-landscape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Review of the Python Data Science Dashboarding Landscape in 2019
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/learning-to-learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How I Learned to Learn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/pydata-landscape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Opinionated and Unofficial Guide to the PyData Ecosystem
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/static-sites-on-dokku/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Static Sites and Apps On Your Own Dokku Server
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/code-style-tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Style Tools
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Skills
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Software Skills
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Importance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/code-formatting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Formatting your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/documentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documenting your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/environment-variables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Data Scientist's Guide to Environment Variables
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/refactoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Refactoring your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/testing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Testing your code
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    People Skills
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            People Skills
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../people-skills/hiring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hiring and Interviewing Data Scientists
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Terminal Hacks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Terminal Hacks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../terminal/cli-tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tools and Upgrades for your CLI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../terminal/pre-commits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using pre-commit git hooks to automate code checks
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Workflow
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Workflow
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/code-review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Practicing Code Review
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/effective-commit-messages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Effective Git Commits in Data Science
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/gitflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Principled Git-based Workflow in Collaborative Data Science Projects
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../supporters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supporters
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#on-differential-computing" class="md-nav__link">
    On differential computing
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#where-differential-computing-gets-used" class="md-nav__link">
    Where differential computing gets used
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-landscape-of-ad-systems" class="md-nav__link">
    The landscape of AD systems
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-makes-jax-special" class="md-nav__link">
    What makes JAX special?
  </a>
  
    <nav class="md-nav" aria-label="What makes JAX special?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#api-compatible-differentiable-computing" class="md-nav__link">
    API-compatible differentiable computing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#api-compatibility-with-the-rest-of-the-pydata-stack" class="md-nav__link">
    API-compatibility with the rest of the PyData stack
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#composable-program-transforms" class="md-nav__link">
    Composable program transforms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-jax-enables-and-doesnt-enable" class="md-nav__link">
    What JAX enables and doesn't enable
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recent-developments" class="md-nav__link">
    Recent developments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-more" class="md-nav__link">
    Learning more
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="differential-computing-with-jax">Differential Computing with JAX</h1>
<p>The proliferation of differential computing tooling has been one of the biggest contributions
from the deep learning world in the 2010-2020 decade.
In this essay, I want to write about JAX, which in my personal opinion
has made the biggest strides forward
for interoperable differential computing in the Python data science world.</p>
<h2 id="on-differential-computing">On differential computing</h2>
<p>Before we go on, we must first ask: what is differential computing all about?</p>
<p>I think at its core, we can think of differential computing as
"computing where derivatives (from calculus) are a first-class citizen".
This is analogous to probabilistic computing,
in which probabilistic constructs
(such as probability distributions and MCMC samplers)
are given "first class" status in a language.
By "first class" status,
I mean that the relevant computing constructs
are a well-developed category of constructs in the language,
with clearly defined interfaces.</p>
<p>In differential computing,
being able to evaluate <em>gradients</em> of a math function
are at the heart of the language.
(How the gradients are used is a matter of application.)
The objective of a differential computing system is to write a program that gets a computer
to automatically evaluate gradients of a math function that we have written in that language.
This is where <em>automatic differentiation</em> (AD) systems come into play.
They take a program, perhaps written as a Python function,
and automatically transform the program into, perhaps, another Python function,
which can be used to evaluate the derivative of the original function.</p>
<p>All of this falls under the paradigm of AD systems, as I mentioned earlier.
Symbolic differentiation can be considered one subclass of AD systems;
this is a point PyMC3 developer <a href="https://brandonwillard.github.io">Brandon Willard</a> would make.
Packages such as <code>autograd</code>
and now <a href="https://github.com/google/jax">JAX</a> (also by the <code>autograd</code> authors)
are another subclass of AD systems,
which leverage the chain rule
and a recorder tape of math operations called in the program
to automatically construct the gradient function.</p>
<h2 id="where-differential-computing-gets-used">Where differential computing gets used</h2>
<p>In case you've found yourself living like a digital hermit for the past decade
(no judgment, sometimes I do fantasize about going offline for a year),
<em>deep learning</em> has been the place where automatic differentiation has been most utilized.
With deep learning, the core technical problem that needs to be solved is
optimizing parameters of a model to minimize some loss function.
It's here where the full set of partial derivatives of the loss function w.r.t. each parameter in the model
can be automatically calculated using an AD system,
and these partial derivatives can be used
to update their respective model parameters in the direction that minimizes loss.</p>
<p>Because deep learning models and their applications proliferated in the 2010-2020 decade,
AD systems were most commonly associated with neural networks and deep learning.
However, that is not the only place where AD systems show up.</p>
<p>For example, AD is used in the Bayesian statistical modelling world.
Hamiltonian Monte Carlo samplers use AD to help the sampler program
identify the direction in which its next MCMC step should be taken.
AD systems can also be used to optimize parameters
of non-neural network models of the world against data,
such as Gaussian Mixture Models and Hidden Markov Models.
We can even use AD in a class of problems called "input design" problems,
where we try to optimize not the <em>parameters</em> of the model w.r.t. some output,
but the <em>inputs</em> (assuming we know how to cast the inputs into some continuous numerical space.)</p>
<h2 id="the-landscape-of-ad-systems">The landscape of AD systems</h2>
<p>So where do AD systems live?
Firstly, they definitely live inside deep learning frameworks such as PyTorch and TensorFlow,
and other deep learning frameworks.
Without an AD system, these two deep learning frameworks would not work.</p>
<p>Secondly, they also live in independent packages.
In Julia, there are two AD packages: one called <code>Zygote.jl</code>, and the other called <code>AutoGrad.jl</code>;
both of them are actively developed.
<code>autograd</code>, which was the reference Python package that <code>AutoGrad.jl</code> was written against,
is also the precursor to JAX, which I think of as automatic differentiation on steroids.</p>
<h2 id="what-makes-jax-special">What makes JAX special?</h2>
<p>With all of that said, the focus of this essay is JAX.
I wanted to bring a bit of focus to JAX
as I think its developers have been doing all the right things thus far in its development,
and I wanted to highlight these as reasons why you might want to use JAX in your next project.</p>
<h3 id="api-compatible-differentiable-computing">API-compatible differentiable computing</h3>
<p>The Python scientific computing stack,
also known as the PyData or SciPy stack in the Python world,
provides a large library of numerical programs that can be composed together into higher order programs.
What JAX provides is a fully API-compatible reimplementation of the stack's differentiable functions,
with what I think is a near-complete coverage of functions.</p>
<p>As such, users familiar with NumPy and SciPy can,
with minimal changes to lines of code,
write <em>automatically differentiable</em> versions of their existing programs,
and develop new programs that are also automatically differentiable.</p>
<p>How does this work?
I have written <a href="https://github.com/ericmjl/dl-workshop">a longer-form collection of teaching materials on this</a>,
but here is a quick example.
If I have a silly program like the following one:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">jax.scipy.special</span> <span class="kn">import</span> <span class="n">cholesky</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">some_function</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="c1"># do stuff with params, for example, a cholesky decomposition:</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="c1"># followed by a sum of sine transform, for whatever reason it might be needed</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">U</span><span class="p">))</span>
</code></pre></div>
<p>I can get the gradient function easily, using JAX's provided <code>grad</code> function:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span>

<span class="n">dsome_function</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">some_function</span><span class="p">)</span>
</code></pre></div>
<p><code>dsome_function</code> has the same function signature as <code>some_function</code>,
but instead of returning a scalar value,
it returns the derivative of <code>some_function</code> w.r.t. <code>params</code> (the first argument),
in the same (and possibly nested) data structure as <code>params</code>.
That is to say, if <code>params</code> were a tuple, or a dictionary, or a list,
or any other native Python construct,
<code>dsome_function</code> would return the same structure.</p>
<p><code>grad</code> can do many more fancy things,
such as differentiating through loops and flow control,
and second through nth-order derivatives,
and I'd encourage you to check out the docs to learn more.
(That is out of scope for this essay, as I'm focusing on high level points.)</p>
<p>Providing <code>grad</code> as a first-class citizen
in an API-compatible fashion with the scientific Python computing stack
makes it very easy to adopt differential computing tooling in one's programs.</p>
<h3 id="api-compatibility-with-the-rest-of-the-pydata-stack">API-compatibility with the rest of the PyData stack</h3>
<p>A design choice made early on by the JAX developers
was full NumPy and SciPy API compatibility,
with minimal differences (mostly in the realm of random number generation)
that are very well-documented.
Incidentally, this practice is also adopted by Dask and CuPy,
which give us distributed and GPU-backed arrays respectively.
This practice reflects a healthy dose of respect
for what already exists and for end-users as well.</p>
<p>I think a contrasting example best illustrates this point.
Consider a PyTorch or TensorFlow array vs. a JAX NumPy array.</p>
<p>To plot a PyTorch array's values in <code>matplotlib</code>, one must first convert it to a NumPy array:</p>
<div class="highlight"><pre><span></span><code><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<p>On the other hand, with JAX:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</code></pre></div>
<p>The syntax with JAX is identical to what one might write with vanilla NumPy.
This is, I think, in part because JAX's developers have also strived
to adhere to <a href="https://numpy.org/neps/nep-0018-array-function-protocol.html">NEP18</a>.
Small API differences introduce micro-friction in programming,
which compound frustration over time;
JAX effectively eliminates that friction by adhering to an existing API
and not playing smartypants with it.</p>
<h3 id="composable-program-transforms">Composable program transforms</h3>
<p>JAX's <code>grad</code> function is merely the "gateway drug" to
this bigger idea of "composable program transforms".
<code>grad</code> is one example of a composable program transform:
that is transforming one program into another in a <em>composable</em> fashion.
Other transforms include <code>vmap</code>, <code>lax.scan</code>, <code>jit</code>, and more.
These all accept Python functions and return Python functions.
<code>jit</code>, in particular, can accelerate a program anywhere from 2-100 fold on a CPU,
depending on what your reasonable baseline comparison is.</p>
<p>In particular, the latter three of the aformentioned transforms
allow for highly performant loop code, written without loops,
that can also be composed together.
In this <a href="https://github.com/ericmjl/dl-workshop/">differential learning workshop</a> that I have been developing,
I provide further details in there, which you can take a look at.</p>
<p>There are other automatic program transformations that are in active development,
and one exciting realm I see is in the probabilistic programming world.
In PyMC3, for example, an automated transform happens when we take our PyMC3 syntax,
which is written in a domain specific language (DSL) implemented in Python,
and transform/compile it into a compute graph that gives us a <em>likelihood</em> function.
It's as if PyMC3 gives us a <code>likelihood(func)</code> analogy to JAX's <code>grad</code> func.
If you've tried writing probabilistic model likelihoods by hand,
you'll know how much of a convenience this is!</p>
<h2 id="what-jax-enables-and-doesnt-enable">What JAX enables and doesn't enable</h2>
<p>JAX as a package doesn't pretend to be a replacement for established deep learning frameworks.
That is because JAX doesn't provide the <em>deep learning</em> abstractions as a first-class citizen;
its focus is on the much more generally useful idea of <em>composable program transformations</em>.
To compare it against a deep learning framework is a bit of a red herring - a distraction away from what JAX enables.</p>
<p>What JAX actually enables is for us to write numerical programs using the NumPy API
that are performant and automatically differentiable.
<code>vmap</code> and <code>lax.scan</code> help us eliminate Python loop overhead in our code;
<code>jit</code> just-in-time compiles code to accelerate it;
<code>grad</code> gives us differentiability,
thus opening the door for us to write
performant optimization routines that solve real world problems.</p>
<p>At work, I have used JAX productively in both neural network and non-neural network settings,
with the unifying theme being gradient-based optimization of model parameters.
With JAX, I can seamlessly move between problem classes
while using the PyData community's idiomatic NumPy API.
We have used JAX to implement
Hierarchical Dirichlet Process autoregressive multivariate Gaussian hidden Markov models (what a mouthful!),
LSTM recurrent neural networks,
graph neural networks,
simple feed-forward neural networks,
linear models, and more...
and train them using the same gradient descent tooling available to us in JAX.</p>
<p>The upside here is that we could hand-craft each model
and tailor it to each problem encountered.
The code was written in a very explicit fashion
that exposed the many layers of abstractions that were sometimes needed.
Noe that this may also be viewed as the downside of writing JAX code --
we had to write a lot of code,
partially because the abstractions we needed weren't already implemented in some cases,
and partially because they aren't easily available in JAX in other cases.</p>
<p>One thing I wanted to highlight though:
leveraging simple tricks learned from the neural network and probabilistic programming worlds
(such as optimizing in unbounded rather than bounded space),
we were able to train covariance matrices in our multivariate Gaussian HMMs
using gradient descent rather than expectation-maximization,
and it <em>just worked</em>.
I found it amazing to see in action.</p>
<p>Now, the lack of deep learning abstractions in JAX
doesn't mean that JAX as a backend to other computing frameworks isn't available!
A flurry of development after JAX's initial release
led to a suite of deep learning libraries and probabilistic programming languages
targeting JAX as an array backend,
because of its provision of a library of Python-compatible composable program transformations.</p>
<p>For deep learning libraries,
an experimental <a href="https://jax.readthedocs.io/en/latest/jax.experimental.stax.html"><code>stax</code></a> module exists inside JAX;
my intern Arkadij Kummer and myself used it productively
in a JAX-based reimplementation of an LSTM model used for protein engineering.
<a href="https://flax.readthedocs.io"><code>flax</code></a>, also developed by Googlers, exists,
and provides a PyTorch-like API that builds on top of the functional programming paradigm encouraged by JAX.
The <a href="https://github.com/google/neural-tangents">Neural Tangents</a> package
for infinitely wide, Bayesian neural networks follows <code>stax</code>'s  idioms,
with well-documented differences (though without reasons given).</p>
<p>For probabilistic programming languages,
even TensorFlow Probability has a JAX backend as an alternative to the TensorFlow backend.
PyMC3, which is built on top of Theano, is getting a JAX-ified Theano backend too,
while <a href="https://github.com/rlouf/mcx"><code>mcx</code></a>, written by a French software developer Rem√≠ Louf,
is a pedagogical PPL written entirely using JAX as a backend too.
Not to forget NumPyro, which is another JAX-based implementation
of the Pyro probabilistic programming language.</p>
<h2 id="recent-developments">Recent developments</h2>
<p>JAX has been actively developed for over two years now,
and as a project, it continues to attract talent to the project.
The originators were Dougal Maclaurin, Matt Johnson, Alex Wiltschko and David Duvenaud
while they were at all at Harvard,
and has since grown to include many prominent Pythonistas
including Jake Vanderplas and Stephan Hoyer on the team.
(There are many more, whose names I don't know very well,
so my apologies in advance if I have left your name out.
For a full list of code contributors,
the <a href="https://github.com/google/jax/graphs/contributors">repository contributors page</a> is the most definitive.)</p>
<h2 id="learning-more">Learning more</h2>
<p>I invested one of my vacation weeks crystallizing my learnings from working with JAX over the past year and a half,
and it's been extremely educational.
If you're interested in reading it,
you can find it at <a href="https://github.com/ericmjl/dl-workshop">my <code>dl-workshop</code> repository on GitHub</a>.
In there, in addition to the original content, which was a workshop on deep learning,
I also try to provide "simple complex examples" of how to use JAX idioms in solving modelling problems.</p>
<p>Besides that, JAX's documentation is quite well-written,
and you can find it at <a href="https://jax.readthedocs.io/en/latest/">jax.readthedocs.io</a>.
In particular, they have a very well-documented suite of "The Sharp Bits" to look out for
when using JAX, geared towards both power users of vanilla NumPy and beginners.
If you're using JAX and run into unexpected behaviour,
I'd strongly encourage you to check out the post -
it'll clear up many misconceptions you might have!</p>
<p>In terms of introductory material, a blog post by Colin Raffel,
titled <a href="https://colinraffel.com/blog/you-don-t-know-jax.html">"You don't know JAX"</a>,
is a very well-written introduction on how to use JAX.
Eric Jang also has a blog post on <a href="https://blog.evjang.com/2019/02/maml-jax.html">implementing meta-learning in JAX</a>,
which I found very educational for both JAX syntax and meta-learning.</p>
<p>While the most flashy advances of the deep learning world came from 2010-2020,
personally think that the most exciting foundational advance of that era
was the development of a general purpose automatic differentiation package like <code>autograd</code> and JAX.
At least for the Python world, it's enabled the writing of arbitrary models
in a highly compatible fashion with the rest of the PyData stack,
with differentiation and native compilation as first class program transformations.
The use of gradients is varied, with much room for creativity;
I'd definitely encourage you to try it out!</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="http://www.shortwhale.com/ericmjl" target="_blank" rel="noopener" title="www.shortwhale.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2Z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/ericmjl" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/ericmjl" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://linkedin.com/in/ericmjl" target="_blank" rel="noopener" title="linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["tabs"], "search": "../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.dff1b7c8.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js"></script>
      
    
  </body>
</html>