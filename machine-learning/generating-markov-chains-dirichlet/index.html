
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../markov-models/">
      
      
        <link rel="next" href="../message-passing/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.2.8">
    
    
      
        <title>Dirichlet Processes and Hidden Markov Model Transition Matrices - Essays on Data Science</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.046329b4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.85d0ee34.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/mermaid@7.1.2/dist/mermaid.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#dirichlet-processes-and-hidden-markov-model-transition-matrices" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Essays on Data Science" class="md-header__button md-logo" aria-label="Essays on Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Essays on Data Science
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Dirichlet Processes and Hidden Markov Model Transition Matrices
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ericmjl/essays-on-data-science" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Essays on Data Science" class="md-nav__button md-logo" aria-label="Essays on Data Science" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Essays on Data Science
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ericmjl/essays-on-data-science" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Computing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Computing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../computing/recursion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recursion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Machine Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Machine Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../computational-bayesian-stats/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Introduction to Probability and Computational Bayesian Statistics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../markov-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markov Models From The Bottom Up, with Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Dirichlet Processes and Hidden Markov Model Transition Matrices
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Dirichlet Processes and Hidden Markov Model Transition Matrices
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lets-generate-markov-sequences-now" class="md-nav__link">
    Let's generate Markov sequences now
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generating-markov-sequences-concentrated-on-a-few-stable-states" class="md-nav__link">
    Generating Markov sequences concentrated on a few stable states
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-of-the-right-concentration-of-states" class="md-nav__link">
    Inference of the right "concentration" of states
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../message-passing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Computational Representations of Message Passing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../reimplementing-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reimplementing and Testing Deep Learning Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../differential-computing-jax/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Differential Computing Explained
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../nngp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Infinitely Wide Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../graph-nets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Attempt at Demystifying Graph Deep Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../llm-dev-guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Developer-First Guide to LLM APIs
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Miscellaneous
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Miscellaneous
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/dashboarding-landscape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Review of the Python Data Science Dashboarding Landscape in 2019
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/learning-to-learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How I Learned to Learn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/pydata-landscape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    An Opinionated and Unofficial Guide to the PyData Ecosystem
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/static-sites-on-dokku/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Static Sites and Apps On Your Own Dokku Server
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../miscellaneous/code-style-tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Style Tools
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Skills
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Software Skills
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Importance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/code-formatting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Formatting your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/documentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documenting your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/environment-variables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A Data Scientist's Guide to Environment Variables
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/refactoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Refactoring your code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../software-skills/testing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Testing your code
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    People Skills
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            People Skills
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../people-skills/hiring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hiring and Interviewing Data Scientists
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Terminal Hacks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Terminal Hacks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../terminal/cli-tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tools and Upgrades for your CLI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../terminal/pre-commits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using pre-commit git hooks to automate code checks
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Workflow
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Workflow
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/code-review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Practicing Code Review
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/effective-commit-messages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Effective Git Commits in Data Science
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/gitflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Principled Git-based Workflow in Collaborative Data Science Projects
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../supporters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supporters
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lets-generate-markov-sequences-now" class="md-nav__link">
    Let's generate Markov sequences now
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generating-markov-sequences-concentrated-on-a-few-stable-states" class="md-nav__link">
    Generating Markov sequences concentrated on a few stable states
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference-of-the-right-concentration-of-states" class="md-nav__link">
    Inference of the right "concentration" of states
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="dirichlet-processes-and-hidden-markov-model-transition-matrices">Dirichlet Processes and Hidden Markov Model Transition Matrices</h1>
<p>How do we construct transition matrices that prioritize re-entry into a constrained set of states? Especially if we don't have perfect knowledge of how many <em>true</em> states there are?</p>
<p>From <a href="https://people.csail.mit.edu/mattjj/thesis/ch3.pdf">Matt Johnson's thesis</a>, I learned exactly how.</p>
<p>Some of us might be used to thinking about transition matrices that have strong diagonals.
That's all good for providing <em>stability</em> in a sequence of transitions.
But if the goal is to provide a model
where the constrained set of states is given priority over the other states,
then what we <em>really</em> need is a transition matrix where the first K <em>columns</em> of the transition matrix
are given priority over the others.</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s1">&#39;retina&#39;</span>
<span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span><span class="p">,</span> <span class="n">vmap</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">lax</span>
<span class="kn">from</span> <span class="nn">jax.scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</code></pre></div>
<p>To generate a transition matrix with this desired property, we can turn to the <a href="https://towardsdatascience.com/behind-the-models-beta-dirichlet-and-gem-distributions-526b11a24359">GEM distribution</a>. The GEM distribution is one way to generate a random vector from a Dirichlet distribution (which is the generalization of a Beta distribution).</p>
<p>You can think of it as stick-breaking, basically. We take a stick of unit length 1, and break it in two according to a draw from a Beta distribution. We record the length of the left part of the stick, and then break the right stick into two according to a draw from a Beta distribution. We then record the new length of the left side and break the right one again and again, <em>ad infinitum</em> or until we have reached a predefined (but finite) number of breaks. The vector of recorded lengths becomes a "weighting" vector. One thing to keep in mind: this weighting vector doesn't necessarily sum to 1, so in order to use the weighting vector in a transition matrix, we do have to normalize it to sum to 1, or we append the remainder of the stick to the end to get it to sum to 1.</p>
<p>Enough said, let's dig in and try simulating this process.</p>
<p>Firstly, we generate a vector of i.i.d. draws from a Beta distribution with parameters <span class="arithmatex"><span class="MathJax_Preview">\alpha = 1</span><script type="math/tex">\alpha = 1</script></span> and <span class="arithmatex"><span class="MathJax_Preview">\beta = 1</span><script type="math/tex">\beta = 1</script></span>.</p>
<div class="highlight"><pre><span></span><code><span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span>  <span class="c1"># for reproducibility</span>
<span class="n">beta_draws</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">beta_draws</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_4_0.png" /></p>
<p>Now, we take this and begin our stick-breaking process. Because it is effectively a for-loop in which each loop iteration uses carryover from the previous loop iteration, I have written it taking advantage of JAX's <code>lax.scan</code> function.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">stick_breaking_weights</span><span class="p">(</span><span class="n">beta_draws</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return weights from a stick breaking process.</span>

<span class="sd">    :param beta_draws: i.i.d draws from a Beta distribution.</span>
<span class="sd">        This should be a row vector.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">weighting</span><span class="p">(</span><span class="n">occupied_probability</span><span class="p">,</span> <span class="n">beta_i</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param occupied_probability: The cumulative occupied probability taken up.</span>
<span class="sd">        :param beta_i: Current value of beta to consider.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">occupied_probability</span><span class="p">)</span> <span class="o">*</span> <span class="n">beta_i</span>
        <span class="k">return</span> <span class="n">occupied_probability</span> <span class="o">+</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight</span>

    <span class="n">occupied_probability</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">weighting</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.</span><span class="p">),</span> <span class="n">beta_draws</span><span class="p">)</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">occupied_probability</span><span class="p">,</span> <span class="n">weights</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">occupied_prob</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">stick_breaking_weights</span><span class="p">(</span><span class="n">beta_draws</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_7_0.png" /></p>
<p>Really cool! We now have a vector of weights, normalized to a probability distribution.</p>
<p>It's worth at this point exploring the effect of varying the <span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span> parameter in the Beta distribution:</p>
<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">bvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
<span class="n">beta_draws</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,)))(</span><span class="n">bvals</span><span class="p">)</span>
<span class="n">occupied_probs</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">stick_breaking_weights</span><span class="p">)(</span><span class="n">beta_draws</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bval</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bvals</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;b = </span><span class="si">{</span><span class="n">bval</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_9_0.png" /></p>
<p>As should be visible, when we increase the <code>b</code> value, we get a less concentrated and flatter distribution compared to when we use a smaller <code>b</code> value. Thus, <code>b</code> acts as a "concentration" parameter. Smaller values means probability mass is concentrated on a smaller number of slots, while larger values means probability mass is diffused across a larger number of slots.</p>
<p>How does this relate to transition matrices in hidden Markov models? Well, a potentially desirable property is that we wish to express is that most of the states tend to move into a certain smaller number of states, thereby <em>concentrating</em> the number of occupied states into a smaller set. This is equivalent to concentrating the transition matrix to a subset of <em>columns</em>. Let's see how we can generate this kind of transition matrix.</p>
<p>Firstly, since transition matrices are square, let's start with a 15x15 transition matrix, i.e. one with 15 states.</p>
<div class="highlight"><pre><span></span><code><span class="n">N_STATES</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">CONCENTRATION</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">beta_draws</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">CONCENTRATION</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_STATES</span><span class="p">,</span> <span class="n">N_STATES</span><span class="p">))</span>
</code></pre></div>
<p>To visualize these i.i.d. Beta-distributed draws, let's use a heatmap.</p>
<div class="highlight"><pre><span></span><code><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">beta_draws</span><span class="p">);</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_13_0.png" /></p>
<p>Keep in mind, this is not the transition matrix just yet. It is the precursor to one!</p>
<p>Next up, on a row-wise basis, we convert each row to a weighting vector, thereby getting back a transition matrix:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_transition_matrix</span><span class="p">(</span><span class="n">beta_draws</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">transition_matrix</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">stick_breaking_weights</span><span class="p">)(</span><span class="n">beta_draws</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_</span><span class="p">,</span> <span class="n">transition_matrix</span>

<span class="n">_</span><span class="p">,</span> <span class="n">transition_matrix</span> <span class="o">=</span> <span class="n">compute_transition_matrix</span><span class="p">(</span><span class="n">beta_draws</span><span class="p">)</span>
</code></pre></div>
<p>And visualizing the transition_matrix...</p>
<div class="highlight"><pre><span></span><code><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">);</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_17_0.png" /></p>
<p>Voilà! We have a transition matrix that has most of the probability mass concentrated in just a few states. Let's calculate the equilibrium distribution:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">equilibrium_distribution</span><span class="p">(</span><span class="n">p_transition</span><span class="p">):</span>
    <span class="n">n_states</span> <span class="o">=</span> <span class="n">p_transition</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">arr</span><span class="o">=</span><span class="n">p_transition</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_states</span><span class="p">),</span>
        <span class="n">values</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_states</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="c1"># Moore-Penrose pseudoinverse = (A^TA)^{-1}A^T</span>
    <span class="n">pinv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="c1"># Return last row</span>
    <span class="k">return</span> <span class="n">pinv</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">eq_distribution</span> <span class="o">=</span> <span class="n">equilibrium_distribution</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eq_distribution</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_20_0.png" /></p>
<p>As should be visible, we spend the majority of time in just a few states, and not too many more.</p>
<p>At this point, it's worth exploring how the "concentration" parameter affects the transition matrix, and hence the equilibrium distribution.</p>
<div class="highlight"><pre><span></span><code><span class="n">CONCENTRATIONS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
<span class="n">N_DIMS</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">beta_draws</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_DIMS</span><span class="p">,</span> <span class="n">N_DIMS</span><span class="p">)))(</span><span class="n">CONCENTRATIONS</span><span class="p">)</span>
<span class="n">beta_draws</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>(5, 30, 30)
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">_</span><span class="p">,</span> <span class="n">transition_matrices</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">compute_transition_matrix</span><span class="p">)(</span><span class="n">beta_draws</span><span class="p">)</span>
<span class="n">eq_distributions</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">equilibrium_distribution</span><span class="p">)(</span><span class="n">transition_matrices</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">conc</span><span class="p">,</span> <span class="n">tmat</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">CONCENTRATIONS</span><span class="p">,</span> <span class="n">transition_matrices</span><span class="p">):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">tmat</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;concentration = </span><span class="si">{</span><span class="n">conc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">conc</span><span class="p">,</span> <span class="n">eq_dist</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">CONCENTRATIONS</span><span class="p">,</span> <span class="n">eq_distributions</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eq_dist</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;concentration = </span><span class="si">{</span><span class="n">conc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_23_0.png" /></p>
<p>As you can see, when the value of <code>b</code> goes up, the more diffuse the transition matrix, and the more evenly spread-out the equilibrium states will be.</p>
<h2 id="lets-generate-markov-sequences-now">Let's generate Markov sequences now</h2>
<p>Now that we know how to generate transition matrices, let's step back and try to see whether the generated Markovian sequences from these transition matrices make sense, i.e. whether they display the desired properties that we seek or not.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="nn">jax.scipy.special</span> <span class="kn">import</span> <span class="n">logit</span>
</code></pre></div>
<p>Firstly, let's try writing the function that generates a Markov sequence given a transition matrix.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">jit</span>

<span class="k">def</span> <span class="nf">markov_sequence</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">p_transition</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate a Markov sequence based on p_init and p_transition.</span>

<span class="sd">    Strategy: leverage categorical distribution.</span>
<span class="sd">    We need to vmap over split PRNGKeys, which will give us the desired number of draws.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p_eq</span> <span class="o">=</span> <span class="n">equilibrium_distribution</span><span class="p">(</span><span class="n">p_transition</span><span class="p">)</span>
    <span class="n">logit_p_eq</span> <span class="o">=</span> <span class="n">logit</span><span class="p">(</span><span class="n">p_eq</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">categorical</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logit_p_eq</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>

    <span class="k">def</span> <span class="nf">draw_state</span><span class="p">(</span><span class="n">prev_state</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">logit</span><span class="p">(</span><span class="n">p_transition</span><span class="p">[</span><span class="n">prev_state</span><span class="p">])</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">categorical</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">state</span>

    <span class="n">keys</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span>
    <span class="n">final_state</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">draw_state</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">keys</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>

<span class="n">markov_sequence</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">markov_sequence</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>

<span class="n">final</span><span class="p">,</span> <span class="n">sequence</span> <span class="o">=</span> <span class="n">markov_sequence</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">transition_matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">final</span><span class="p">,</span> <span class="n">sequence</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code><span class="p">(</span><span class="nx">Array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="nx">dtype</span><span class="p">=</span><span class="nx">int32</span><span class="p">),</span>
<span class="w"> </span><span class="nx">Array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">        </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">        </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="nx">dtype</span><span class="p">=</span><span class="nx">int32</span><span class="p">))</span>
</code></pre></div>

<p>Now, I think we can generate a bunch of Markov chain sequences using <code>vmap</code>.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">markov_seq_vmappable</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">transition_matrix</span><span class="p">):</span>
    <span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="k">return</span> <span class="n">markov_sequence</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">transition_matrix</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">sequences</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">markov_seq_vmappable</span><span class="p">)(</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">transition_matrices</span><span class="p">)</span>
</code></pre></div>
<p>Let's plot them out!</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">seq</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">sequences</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)),</span> <span class="n">seq</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_32_0.png" /></p>
<p>As should be visible, as we increase the concentration parameter (really, I think this should be renamed as a "diffusion" parameter),
the number of states that we would typically occupy increases. At smaller values of the concentration parameter, the number of states we would typically occupy decreases.</p>
<h2 id="generating-markov-sequences-concentrated-on-a-few-stable-states">Generating Markov sequences concentrated on a few stable states</h2>
<p>We've thus far generated transition matrices that are biased towards a few states, but they do tend to be jumpy, as the above scatterplots show. In other words, we have not yet generated matrices that allow for <em>stability inside a state</em>. Stability inside a state is generated from strong diagonals. We can engineer this in the generation of the matrix by leveraging (once again) the Beta distribution. Specifically, the generative story here is that each row of the transition matrix is generated by stick-breaking, but the diagonals are replaced by a Beta draw that is biased towards high probabilities. Let's see this in action for one transition matrix.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">diagonal_draws</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">bias_factor</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">bias_factor</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">dd</span> <span class="o">=</span> <span class="n">diagonal_draws</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">bias_factor</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_DIMS</span><span class="p">,))</span>
<span class="n">dom_diag_transition_matrix</span> <span class="o">=</span> <span class="n">transition_matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">diagflat</span><span class="p">(</span><span class="n">dd</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">normalize_prob_vect</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">v</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">normalize_transition_matrix</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">vmap</span><span class="p">(</span><span class="n">normalize_prob_vect</span><span class="p">)(</span><span class="n">transition_matrix</span><span class="p">)</span>

<span class="n">dom_diag_transition_matrix</span> <span class="o">=</span> <span class="n">normalize_transition_matrix</span><span class="p">(</span><span class="n">dom_diag_transition_matrix</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">dom_diag_transition_matrix</span><span class="p">);</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_36_0.png" /></p>
<p>Now given <em>this</em> transition matrix, let's generate new sequences:</p>
<div class="highlight"><pre><span></span><code><span class="n">_</span><span class="p">,</span> <span class="n">seq</span> <span class="o">=</span> <span class="n">markov_sequence</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">dom_diag_transition_matrix</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_38_0.png" /></p>
<p>As is visible from the plot above, we get sequences that tend to stay inside a state, and when they do venture out to unfavoured states (e.g. state 5), they quickly return back to a favoured state.</p>
<p>Now, let's see what kind of sequences we get when we use the same dominant diagonal with different concentration parameters.</p>
<p>Firstly, we generate a bunch of dominant diagonal matrices:</p>
<div class="highlight"><pre><span></span><code><span class="n">keys</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">diagonals</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">diagonal_draws</span><span class="p">,</span> <span class="n">bias_factor</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_DIMS</span><span class="p">,)))(</span><span class="n">keys</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_dominant_diagonal</span><span class="p">(</span><span class="n">p_transition</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">):</span>
    <span class="n">p_transition</span> <span class="o">=</span> <span class="n">p_transition</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">diagflat</span><span class="p">(</span><span class="n">diagonal</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">normalize_transition_matrix</span><span class="p">(</span><span class="n">p_transition</span><span class="p">)</span>

<span class="n">dom_diag_transition_matrices</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">create_dominant_diagonal</span><span class="p">)(</span><span class="n">transition_matrices</span><span class="p">,</span> <span class="n">diagonals</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">mat</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">dom_diag_transition_matrices</span><span class="p">):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_40_0.png" /></p>
<p>Now, we generate a bunch of sequences.</p>
<div class="highlight"><pre><span></span><code><span class="n">_</span><span class="p">,</span> <span class="n">sequences</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">markov_seq_vmappable</span><span class="p">)(</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dom_diag_transition_matrices</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">conc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">sequences</span><span class="p">,</span> <span class="n">CONCENTRATIONS</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)),</span> <span class="n">seq</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;concentration = </span><span class="si">{</span><span class="n">conc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_42_0.png" /></p>
<p>As should be visible from here, we now generate sequences that have a much higher propensity to stay within their own state, rather than jump around. Additionally, when there are more states "available" (i.e. concentration runs higher), we also see them stay within their own state rather than jump back down to the favoured states.</p>
<h2 id="inference-of-the-right-concentration-of-states">Inference of the right "concentration" of states</h2>
<p>Given the transition matrix, can we infer the concentration parameter that best describes it? This is what we're going to try out here.</p>
<p>We start with a vanilla transition matrix generated from a <code>concentration = 1</code> setting, with no dominant diagonals. This is the easier setting to begin with:</p>
<div class="highlight"><pre><span></span><code><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">transition_matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_45_0.png" /></p>
<p>Each row of the transition matrix is generated by running a stick breaking process forward from Beta distributed draws. We can run the process backwards to get back our Beta-distributed matrix. Because there's division involved, I have opted to operate in logarithmic space instead, to avoid over/under-flow issues.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">lax</span>
<span class="k">def</span> <span class="nf">beta_draw_from_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">beta_from_w</span><span class="p">(</span><span class="n">accounted_probability</span><span class="p">,</span> <span class="n">weights_i</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param accounted_probability: The cumulative probability acounted for.</span>
<span class="sd">        :param weights_i: Current value of weights to consider.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">accounted_probability</span>
        <span class="n">log_denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">denominator</span><span class="p">)</span>

        <span class="n">log_beta_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">weights_i</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_denominator</span>

        <span class="n">newly_accounted_probability</span> <span class="o">=</span> <span class="n">accounted_probability</span> <span class="o">+</span> <span class="n">weights_i</span>

        <span class="k">return</span> <span class="n">newly_accounted_probability</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_beta_i</span><span class="p">)</span>
    <span class="n">final</span><span class="p">,</span> <span class="n">betas</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">beta_from_w</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.</span><span class="p">),</span> <span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">final</span><span class="p">,</span> <span class="n">betas</span>
</code></pre></div>
<p>And now, to sanity-check that it works:</p>
<div class="highlight"><pre><span></span><code><span class="n">beta_draw</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,))</span>
<span class="n">_</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">stick_breaking_weights</span><span class="p">(</span><span class="n">beta_draw</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">beta_draw_hat</span> <span class="o">=</span> <span class="n">beta_draw_from_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">beta_draw</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;original&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">beta_draw_hat</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;recovered&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_49_0.png" /></p>
<p>Up till the last few values, we are basically able to recover the beta distributed draw that generated the matrix. The fundamental problem we're facing here is that when we are faced with a probability vector, we're still missing the "last stick" which would give us an accurate estimate of the originals. As such, only the first few are really accurate, and the accuracy of beta draw recovery goes down as we go across the vector.</p>
<p>Let's now apply the function to every row in the transition matrix.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">recover_beta</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">vmap</span><span class="p">(</span><span class="n">beta_draw_from_weights</span><span class="p">)(</span><span class="n">transition_matrix</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">_</span><span class="p">,</span> <span class="n">recovered_betas</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">recover_beta</span><span class="p">)(</span><span class="n">transition_matrices</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">idx</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">recovered_betas</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">beta_draws</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>&lt;AxesSubplot: &gt;
</code></pre></div>

<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_52_1.png" /></p>
<p>Matches what we saw above - we're doing an almost-OK job here.</p>
<p>Now, we can evaluate the logpdf of the matrix.
Because each entry in the recovered betas matrix is an i.i.d. draw from the Beta distribution,
and because row-wise the first 3-5 elements are accurately estimatable backwards from the weights,
we will estimate the concentration parameter using only the first three columns of betas from the matrix.</p>
<p>Test-driving the syntax below...</p>
<div class="highlight"><pre><span></span><code><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">recovered_betas</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">9</span><span class="p">))</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code><span class="nx">Array</span><span class="p">(</span><span class="m m-Double">153.58696</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="p">=</span><span class="nx">float32</span><span class="p">)</span>
</code></pre></div>

<p>Looks good! Let's now define a function for the logpdf.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transition_matrix_logpdf</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">,</span> <span class="n">concentration</span><span class="p">,</span> <span class="n">num_cols</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">beta_recovered</span> <span class="o">=</span> <span class="n">recover_beta</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">)</span>
    <span class="n">logp</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">beta_recovered</span><span class="p">[:,</span> <span class="p">:</span><span class="n">num_cols</span><span class="p">],</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">concentration</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">logp</span><span class="p">)</span>

<span class="n">transition_matrix_logpdf</span><span class="p">(</span><span class="n">transition_matrices</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code><span class="nx">Array</span><span class="p">(</span><span class="m m-Double">20.504595</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="p">=</span><span class="nx">float32</span><span class="p">)</span>
</code></pre></div>

<p>Just to see if this is a gradient optimizable problem, let's plot a range of concentration values, and see what happens.</p>
<div class="highlight"><pre><span></span><code><span class="n">log_conc_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">conc_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_conc_range</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">loglike_range</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">,</span> <span class="n">log_conc_range</span><span class="p">):</span>
    <span class="n">conc_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_conc_range</span><span class="p">)</span>
    <span class="n">ll</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">transition_matrix_logpdf</span><span class="p">,</span> <span class="n">transition_matrix</span><span class="p">))(</span><span class="n">conc_range</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ll</span>

<span class="n">ll</span> <span class="o">=</span> <span class="n">loglike_range</span><span class="p">(</span><span class="n">transition_matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">log_conc_range</span><span class="p">)</span>

<span class="n">lls</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">loglike_range</span><span class="p">,</span> <span class="n">log_conc_range</span><span class="o">=</span><span class="n">log_conc_range</span><span class="p">))(</span><span class="n">transition_matrices</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">CONCENTRATIONS</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ll</span><span class="p">,</span> <span class="n">conc</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lls</span><span class="p">,</span> <span class="n">CONCENTRATIONS</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">conc_range</span><span class="p">,</span> <span class="n">ll</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;concentration = </span><span class="si">{</span><span class="n">conc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_58_0.png" /></p>
<p>Not bad! Visually, it appears that we do pretty good in recovering the maximum likelihood value for most of the entries, but for concentration = 20, it's more difficult to do so.</p>
<p>Let's confirm by extracting the concentration at which we have maximum log-likelihood.</p>
<div class="highlight"><pre><span></span><code><span class="n">maxes</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">)(</span><span class="n">lls</span><span class="p">)</span>
<span class="n">mle_estimates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">conc_range</span><span class="p">,</span> <span class="n">maxes</span><span class="p">)</span>
<span class="n">mle_estimates</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code><span class="nx">Array</span><span class="p">([</span><span class="w"> </span><span class="m m-Double">0.930245</span><span class="w"> </span><span class="p">,</span><span class="w">  </span><span class="m m-Double">3.1544516</span><span class="p">,</span><span class="w">  </span><span class="m m-Double">5.2817965</span><span class="p">,</span><span class="w"> </span><span class="m m-Double">10.019469</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="m m-Double">16.261148</span><span class="w"> </span><span class="p">],</span><span class="w">      </span><span class="nx">dtype</span><span class="p">=</span><span class="nx">float32</span><span class="p">)</span>
</code></pre></div>

<p>Great! Doing this brute-force is all nice and good, but one of the points of JAX is that we get to do gradient descent easily. So now, let's try to perform gradient-based optimization :).</p>
<p>We start by first defining a loss as a function of the log of the concentration. (We use the log so that when we do gradient optimization, we can be in an unbounded space.) We also define the gradient of the loss function.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">loglike_loss</span><span class="p">(</span><span class="n">log_concentration</span><span class="p">,</span> <span class="n">transition_matrix</span><span class="p">):</span>
    <span class="n">concentration</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_concentration</span><span class="p">)</span>
    <span class="n">ll</span> <span class="o">=</span> <span class="n">transition_matrix_logpdf</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">,</span> <span class="n">concentration</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">ll</span>

<span class="n">loglike_loss</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">loglike_loss</span><span class="p">)</span>
<span class="n">dloglike_loss</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loglike_loss</span><span class="p">)</span>
</code></pre></div>
<p>Next up, we do the loop. Instead of writing an explicit for-loop, we are going to some JAX trickery here:</p>
<ol>
<li>We write the loop taking advantage of <code>lax.scan</code>, which allows us to leverage the previous state to get back parameters to optimize.</li>
<li>We also vmap our training loop over all 5 matrices, starting with the same log concentration starting point. This allows us to essentially train five models at one shot. (I could have <code>pmap</code>-ed it, but I really only have one CPU and one GPU on my computer.)</li>
<li>Since the result is a vmapped, we have a collection of final states and historical states (which we can post-process post-hoc). Hence, we can vmap <code>get_params</code> over final states to get back the vector of final states (from a constant initial state).</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">jax.example_libraries.optimizers</span> <span class="kn">import</span> <span class="n">adam</span>

<span class="n">init</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">get_params</span> <span class="o">=</span> <span class="n">adam</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">log_conc_start</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">prev_state</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">dloss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;One step in the training loop.&quot;&quot;&quot;</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">(</span><span class="n">prev_state</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">dloss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">prev_state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">state</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">,</span> <span class="n">dloss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The training loop for one transition matrix.&quot;&quot;&quot;</span>
    <span class="n">stepfunc</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">transition_matrix</span><span class="p">,</span> <span class="n">dloss</span><span class="o">=</span><span class="n">dloss</span><span class="p">)</span>
    <span class="n">stepfunc</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">stepfunc</span><span class="p">)</span>

    <span class="n">state</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">final_state</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">stepfunc</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_steps</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">states</span>

<span class="n">trainfunc</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">log_conc_start</span><span class="p">,</span> <span class="n">dloss</span><span class="o">=</span><span class="n">dloglike_loss</span><span class="p">)</span>
<span class="n">trainfunc</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">trainfunc</span><span class="p">)</span>
<span class="c1"># Train across all transition matrices!</span>
<span class="n">final_states</span><span class="p">,</span> <span class="n">states_history</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">trainfunc</span><span class="p">)(</span><span class="n">transition_matrices</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">get_params</span><span class="p">)(</span><span class="n">final_states</span><span class="p">))</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code><span class="nx">Array</span><span class="p">([</span><span class="w"> </span><span class="m m-Double">0.9300743</span><span class="p">,</span><span class="w">  </span><span class="m m-Double">3.155341</span><span class="w"> </span><span class="p">,</span><span class="w">  </span><span class="m m-Double">5.2777195</span><span class="p">,</span><span class="w"> </span><span class="m m-Double">10.022282</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="m m-Double">16.264479</span><span class="w"> </span><span class="p">],</span><span class="w">      </span><span class="nx">dtype</span><span class="p">=</span><span class="nx">float32</span><span class="p">)</span>
</code></pre></div>

<p>We can also get the history by <code>vmap</code>-ing <code>get_params</code> over <code>all_states</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">log_concentration_history</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">get_params</span><span class="p">)(</span><span class="n">states_history</span><span class="p">)</span>

<span class="k">for</span> <span class="n">concentration</span><span class="p">,</span> <span class="n">history</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">CONCENTRATIONS</span><span class="p">,</span> <span class="n">log_concentration_history</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">history</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">concentration</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Concentration Value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../generating-markov-chains-dirichlet_files/generating-markov-chains-dirichlet_66_0.png" /></p>
<p>Now, if you're wondering how I knew 200 steps would be sufficient for convergence <em>a priori</em>, I didn't :). I had originally tried 1000 steps before staring at the concentration curves, at which point I then knew 200 was sufficient. So... no magic there.</p>
<h2 id="summary">Summary</h2>
<p>This was a bit of a whirlwind tour of a notebook, in that there were many concepts and ideas tied together into one "project".</p>
<p>With respect to HMMs, it's super important to have a proper mental model of each of its components. In the case of <em>expressing</em> the idea that we have a restricted number of states, we may <em>engineer</em> this into the model by taking advantage of column-wise heaviness in a restricted subset of states. This is mathematically most naturally incorporated by composint together row-wise Dirichlet-distributed probability arrays. We can also mathematically <em>engineer</em> consistency in states by taking advantage of high Beta-distributed values. Compose the two together, and we get a transition matrix that favours entry into a small number of states with stability in there.</p>
<p>Beyond that lesson, we saw the power of composable programs using JAX. <code>vmap</code>, <code>jit</code>, <code>lax.scan</code>, and more from the JAX toolkit gives us the ability to write performant programs that sort of "just make sense", once you know what their idioms are. Specifically:</p>
<ul>
<li><code>vmap</code> is a vanilla for-loop, processing an elementary function over an axis of an array.</li>
<li><code>lax.scan</code> is a carry-over for-loop, processing the result of a previous iteration, with accumulation of history as well.</li>
<li><code>jit</code> gives you just-in-time compilation of a function.</li>
<li><code>grad</code> gives you gradients of any arbitrary function written in a JAX-compatible, pure functional fashion.</li>
</ul>
<p>In particular, getting used to the <code>lax.scan</code> idioms has been a literal door-opener. We can now write really performant loops that use results from previous iterations, such as a gradient descent training loop or an MCMC sampler. Using <code>lax.scan</code>, we wrote:</p>
<ul>
<li>A Markov chain state generator</li>
<li>A generator of Dirichlet-distributed weights from i.i.d. Beta distribution draws</li>
<li>A reverse generator/estimator of Beta distribution draws from Dirichlet-distributed weights (with some inaccuracies of course, due to a lack of information).</li>
<li>A fully-compiled gradient descent training loop that ran extremely fast.</li>
</ul>
<p>And using <code>vmap</code>, we were able to do all sorts of vanilla loops, but the one I want to highlight is our ability to <code>vmap</code> the compiled training loop across multiple transition matrices. The fact that this <em>actually</em> works never has left me in awe. Props to the JAX team here! Opens the door to <code>vmap</code>-ing training loops across random starting points (i.e. a split PRNGKey, much like what we did in the HMM state generator).</p>
<p>The trade-off is that we don't get nice progress bars, of course, which require that we break out of the compiled loop to show the current state. But the compilation speedups provided the opportunity to build our compiled tensor program end-to-end. We could verify first that things ran correctly on a moderately-sized number of iterations, before finally estimating how long we would need to go until convergence and letting the program run on its own. I'm sure this little change isn't too hard to adapt to, but will give you access to a whole new world of differential tensor programming that is just <em>cool</em>!</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">watermark</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code><span class="nx">Last</span><span class="w"> </span><span class="nx">updated</span><span class="p">:</span><span class="w"> </span><span class="mi">2022</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">23</span><span class="nx">T14</span><span class="p">:</span><span class="mi">38</span><span class="p">:</span><span class="m m-Double">05.144500</span><span class="o">-</span><span class="mi">05</span><span class="p">:</span><span class="mi">00</span>

<span class="nx">Python</span><span class="w"> </span><span class="nx">implementation</span><span class="p">:</span><span class="w"> </span><span class="nx">CPython</span>
<span class="nx">Python</span><span class="w"> </span><span class="nx">version</span><span class="w">       </span><span class="p">:</span><span class="w"> </span><span class="m m-Double">3.10.8</span>
<span class="nx">IPython</span><span class="w"> </span><span class="nx">version</span><span class="w">      </span><span class="p">:</span><span class="w"> </span><span class="m m-Double">8.7.0</span>

<span class="nx">Compiler</span><span class="w">    </span><span class="p">:</span><span class="w"> </span><span class="nx">GCC</span><span class="w"> </span><span class="m m-Double">10.4.0</span>
<span class="nx">OS</span><span class="w">          </span><span class="p">:</span><span class="w"> </span><span class="nx">Linux</span>
<span class="nx">Release</span><span class="w">     </span><span class="p">:</span><span class="w"> </span><span class="m m-Double">5.15.0</span><span class="o">-</span><span class="mi">53</span><span class="o">-</span><span class="nx">generic</span>
<span class="nx">Machine</span><span class="w">     </span><span class="p">:</span><span class="w"> </span><span class="nx">x86_64</span>
<span class="nx">Processor</span><span class="w">   </span><span class="p">:</span><span class="w"> </span><span class="nx">x86_64</span>
<span class="nx">CPU</span><span class="w"> </span><span class="nx">cores</span><span class="w">   </span><span class="p">:</span><span class="w"> </span><span class="mi">8</span>
<span class="nx">Architecture</span><span class="p">:</span><span class="w"> </span><span class="mi">64</span><span class="nx">bit</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">watermark</span> <span class="o">--</span><span class="n">iversions</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code><span class="n">jax</span><span class="w">       </span><span class="o">:</span><span class="w"> </span><span class="mf">0.4</span><span class="o">.</span><span class="mi">1</span>
<span class="n">seaborn</span><span class="w">   </span><span class="o">:</span><span class="w"> </span><span class="mf">0.12</span><span class="o">.</span><span class="mi">1</span>
<span class="n">matplotlib</span><span class="o">:</span><span class="w"> </span><span class="mf">3.6</span><span class="o">.</span><span class="mi">2</span>
</code></pre></div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="http://www.shortwhale.com/ericmjl" target="_blank" rel="noopener" title="www.shortwhale.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2Z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/ericmjl" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/ericmjl" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://linkedin.com/in/ericmjl" target="_blank" rel="noopener" title="linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["tabs"], "search": "../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.dff1b7c8.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js"></script>
      
    
  </body>
</html>